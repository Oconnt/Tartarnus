# http基础面试题

## 1、get和post请求的区别

1.GET请求在浏览器刷新或者回退的时候是没危险的。POST的话数据会被重新提交。

2.长度限制：当发送请求时，GET请求一般是向URL添加参数数据，URL的最大长度是2048个字符；

POST请求一般参数不在请求URL中，而在body中。

3.GET可以被书签收藏，POST不行

4.GET可以存在缓存中，POST不行

5.GET会将数据存在浏览器的历史中，POST不会

6.GET 编码格式只能用ASCII码，POST没有限制

7.GET 数据类型application/x-www-form-urlencoded,POST是application/x-www-form-urlencoded或者multipart/form-data。

8.GET 和POST在请求的时候：

GET 是将数据中的hearder 和 data 一起发送给服务端，返回200code

POST 是先将hearder发给服务器返回100continue，再发送data给到服务器，返回200

9.GET 就发送了一个TCP数据包给服务器，POST发送了两次TCP数据包给服务器。

## 2、HTTP 和 HTTPS 的区别？

1. 安全性：HTTP是明文传输数据的协议，数据在传输过程中不加密，容易被窃听和篡改。而HTTPS通过使用SSL/TLS协议进行加密，确保数据在传输过程中的安全性和完整性。
2. 默认端口：HTTP使用默认端口80进行通信，而HTTPS使用默认端口443进行通信。
3. 连接方式：HTTP使用无状态的连接方式，即每次请求与响应之间没有持久的连接。而HTTPS可以使用持久连接，提供更好的性能。
4. 证书：HTTPS使用证书来验证服务器的身份，并建立安全连接。服务器需要获得可信的数字证书，而HTTP没有类似的证书验证机制。
5. URL前缀：HTTP的URL以"http://"开头，而HTTPS的URL以"https://"开头。
6. 加密算法：HTTPS使用SSL/TLS协议进行数据加密，支持多种加密算法，如RSA、AES等。而HTTP没有加密处理。
7. 性能：由于HTTPS需要进行加密和解密操作，相比HTTP而言，会带来一定的性能开销。HTTPS比起HTTP会消耗更多的计算资源和网络带宽。

### 2.1、什么是http？什么是https？

http协议是超文本传输协议，通常用于web浏览器和web服务器传输数据，HTTP协议以明文方式发送内容，不提供任何方式的数据加密

https协议是超文本安全传输协议，通常是基于http + ssl/tls来实现，它使用公钥加密来确保客户端和服务器之间的通信不被窃听或篡改，

客户端和服务器之间进行握手过程，交换加密密钥，确保加密通道的建立。



## 3、浏览器输入网址以后都做了哪些动作？

1. URL 解析：浏览器会解析输入的网址（URL），提取出协议（如HTTP、HTTPS）、主机名（域名）、端口号、路径、查询参数等信息。
2. DNS 解析：浏览器将主机名转换为对应的 IP 地址。它会向本地 DNS 缓存查询，如果没有缓存则会发起 DNS 查询请求到 DNS 服务器，并获取到对应的 IP 地址。
3. 建立网络连接：浏览器通过 TCP/IP 协议与目标服务器建立网络连接。它会使用获取到的 IP 地址和端口号建立 socket 连接。
4. 发起 HTTP 请求：浏览器向目标服务器发送 HTTP 请求。请求中包含方法（GET、POST等）、路径、头部信息、请求体（例如表单数据或请求的内容）等。
5. 接收响应：目标服务器收到请求后，会根据请求进行处理，并生成相应的 HTTP 响应。服务器将响应报文发送回浏览器。
6. 处理响应：浏览器接收到服务器的响应后，会根据响应的状态码（如200、404等）来判断请求是否成功。同时，浏览器会解析响应报文中的头部信息和响应体，以获取所需的数据。

## 4、http协议的缓存策略有哪些？

#### **得分点**

​    强制缓存、协商缓存

#### **参考答案**

**标准回答**

​    HTTP协议的缓存策略有两种，分别是强制缓存和协商缓存，强制缓存的优先级大于协商缓存。强制缓存是服务器告诉浏览器一个缓存时间，在缓存时间内，下次请求，直接用缓存，不在时间内，执行协商缓存策略。协商缓存是让客户端与服务器之间能实现缓存文件是否更新的验证、提升缓存的复用率，将缓存信息中的Etag和Last-Modified字段通过请求发送给服务器，由服务器校验。如果文件没有改变，那么直接返回304状态，继续使用浏览器缓存。

**加分回答**

​    HTTP协议的缓存策略是浏览器每次发起请求时，先在本地缓存中查找结果以及缓存标识，根据缓存标识来判断是否使用本地缓存。如果缓存有效，则使用本地缓存，否则，则向服务器发起请求并携带缓存标识。HTTP协议的缓存策略分两种：强制缓存和协商缓存，而强制缓存优先级大于协商缓存。

- 强制缓存：服务器告诉浏览器一个缓存时间，在缓存时间内，下次请求，直接用缓存，不在时间内，执行比较缓存策略。 
- 协商缓存：让客户端与服务器之间能实现缓存文件是否更新的验证、提升缓存的复用率，将缓存信息中的Etag和Last-Modified
  通过请求发送给服务器，由服务器校验。如果文件没有改变，那么直接返回304状态，继续使用浏览器缓存。 

HTTP缓存都是从第二次请求开始的：

- 第一次请求资源时，服务器返回资源，并在响应头首部中回传资源的缓存策略。 
- 第二次请求时，浏览器判断这些请求参数，击中强缓存就直接返回状态码200，否则就把请求参数加到请求头首部中传给服务器，看是否击中协商缓存，击中则返回304，否则服务器会返回新的资源。 

#### **延伸阅读**

强制缓存：

- 强缓存命中则直接读取浏览器本地的资源，在network中显示的是from memory或者from disk。 
- 控制强制缓存的字段有：Cache-Control（http1.1）和Expires（http1.0）。 
- Cache-control是一个相对时间，用以表达自上次请求正确的资源之后的多少秒的时间段内缓存有效。 
- Expires是一个绝对时间。用以表达在这个时间点之前发起请求可以直接从浏览器中读取数据，而无需发起请求。 
- Cache-Control的优先级比Expires的优先级高。前者的出现是为了解决Expires在浏览器时间被手动更改导致缓存判断错误的问题。如果同时存在则使用Cache-control。 

协商缓存：

- 协商缓存的状态码由服务器决策返回200或者304 
- 当浏览器的强缓存失效的时候或者请求头中设置了不走强缓存，并且在请求头中设置了If-Modified-Since或者 If-None-Match的时候，会将这两个属性值到服务端去验证是否命中协商缓存，如果命中了协商缓存，会返回 304 状态，加载浏览器缓存，并且响应头会设置 Last-Modified或者ETag属性。 
- 对比缓存在请求数上和没有缓存是一致的，但如果是 304 的话，返回的仅仅是一个状态码而已，并没有实际的文件内容，因此在响应体体积上的节省是它的优化点。 
- 协商缓存有2组字段(不是两个)，控制协商缓存的字段有：Last-Modified/If-Modified-since（http1.0）和Etag/If-None-match（http1.1）。 
- Last-Modified/If-Modified-since表示的是服务器的资源最后一次修改的时间。Etag/If-None-match表示的是服务器资源的唯一标识，只要资源变化，Etag就会重新生成。 
- Etag/If-None-match的优先级比Last-Modified/If-Modified-since高。

## 5、IP协议的首部结构 

第一个4字节： 版本号；首部长度； 服务类型；总长度；

第二个4字节：标识；标志；片偏移；

第三个4字节：生存时间；协议；校验和；

第四个4字节：源ip地址；

第五个4字节：目的ip地址；

## 6、什么是session，什么是cookie？他们的区别是什么

在网络应用程序中，Session 和 Cookie 是常见的用于跟踪用户状态和存储用户数据的机制。

**Session**：

- Session 是服务器端存储用户数据的一种机制。它通过在服务器上创建一个唯一的会话标识符（Session ID）来跟踪用户的会话状态。
- 当用户首次访问服务器时，服务器会为该用户创建一个唯一的 Session ID，并将该 ID 存储在服务器端。然后，将该 Session ID 发送给客户端，并且通常以 Cookie 的形式存储在客户端。
- 用户再次访问服务器时，会携带上之前存储的 Session ID。服务器通过 Session ID 辨别用户，并从服务器端存储的 Session 数据中获取用户的状态和数据。

**Cookie**：

- Cookie 是一种客户端存储数据的机制。它由服务器生成并在客户端以文本文件的形式存储。一个 Cookie 包含了键值对，用于存储有关用户和网站的信息。
- 当用户首次访问服务器时，服务器可以通过响应头将 Cookie 发送给客户端，并存储在客户端的浏览器中。
- 当用户再次请求同一网站时，浏览器会自动将之前存储的 Cookie 附加在请求头中发送给服务器。服务器可以读取 Cookie 中的数据，了解用户的状态和偏好。

**区别**：

- 存储位置：Session 数据存储在服务器端，而 Cookie 存储在客户端的浏览器中。
- 容量限制：Session 数据可以存储较大量的数据，而 Cookie 的容量通常有限制（一般为几 KB）。
- 安全性：由于 Session 数据存储在服务器端，相对较安全。而 Cookie 存储在客户端，可能会被篡改或窃取。
- 生命周期：Session 可以设定失效时间，可以在浏览器关闭后失效。而 Cookie 可以设置过期时间，可以在浏览器关闭后仍然存在。

常见做法是，服务器使用 Session 跟踪用户的登录状态、购物车等敏感信息，而使用 Cookie 存储一些非敏感的用户偏好设置。

## 7、说说BIO/NIO/AIO的区别？

**BIO**：同步阻塞IO，每一个客户端连接，服务端都会对应一个处理线程，对于没有分配到处理线程的连接就会被阻塞或者拒绝。相当于是**一个连接一个线程**。

![img](https://pic3.zhimg.com/80/v2-0affbc4be566b2cea22d4f3efcc421fe_720w.webp)

**NIO**：同步非阻塞IO，基于Reactor模型，客户端和channel进行通信，channel可以进行读写操作，通过多路复用器selector来轮询注册在其上的channel，而后再进行IO操作。这样的话，在进行IO操作的时候再用一个线程去处理就可以了，也就是**一个请求一个线程**。

![img](https://pic3.zhimg.com/80/v2-6ebe35e193809e4b888cb95b56b0d8f2_720w.webp)

**AIO**：异步非阻塞IO，相比NIO更进一步，完全由操作系统来完成请求的处理，然后通知服务端开启线程去进行处理，因此是**一个有效请求一个线程**。



## 8、http的keepalive和tcp的keepalive有什么区别？

1. **HTTP Keep-Alive** 是 **应用层优化**，用于 **复用TCP连接** 发送多个HTTP请求，减少握手延迟。
2. **TCP Keepalive** 是 **传输层保活机制**，用于 **检测连接是否有效**，避免因网络问题导致僵死连接占用资源。

两者可同时使用：HTTP复用连接时，TCP层通过Keepalive确保底层连接健康。

## 9、HTTP/1.0、HTTP/1.1、HTTP/2.0 和 HTTP/3.0** 的核心特性对比及新增功能总结

### **1. HTTP/1.0（1996年）**
- **基础特性**：  
  - 无连接：每次请求需新建/关闭TCP连接（高延迟）。  
  - 无状态：每个请求独立，无上下文记忆。  
- **新增功能**：  
  - **请求头/响应头**：支持 `Content-Type`、`User-Agent` 等头部字段。  
  - **缓存控制**：通过 `Expires` 和 `Pragma` 实现简单缓存。  
  - **状态码**：引入 `200`、`404` 等基础状态码。  

**问题**：频繁建立连接导致性能低下。

---

### **2. HTTP/1.1（1997年，主流版本）**
- **核心改进**：  
  - **持久连接（Keep-Alive）**：默认复用TCP连接（`Connection: keep-alive`），减少握手开销。  
  - **管道化（Pipelining）**：允许连续发送多个请求（但响应必须按序返回，易阻塞）。  
  - **分块传输**：支持 `Transfer-Encoding: chunked`，流式传输大文件。  
  - **缓存增强**：引入 `Cache-Control`、`ETag`、`If-None-Match` 等精细缓存策略。  
  - **Host头**：支持虚拟主机（单IP多域名）。  
  - **范围请求**：`Range` 和 `Content-Range` 支持断点续传。  

**问题**：队头阻塞（Head-of-Line Blocking）、冗余头部。

---

### **3. HTTP/2.0（2015年，基于SPDY）**
- **核心改进**：  
  - **二进制分帧**：将数据拆分为二进制帧（Headers/Data Frame），提升解析效率。  
  - **多路复用（Multiplexing）**：一个TCP连接并行传输多个请求/响应，解决队头阻塞。  
  - **头部压缩（HPACK）**：减少冗余头部大小。  
  - **服务器推送（Server Push）**：服务器可主动推送资源（如CSS/JS）。  
  - **流优先级**：为不同资源分配优先级（如优先加载HTML）。  

**问题**：仍依赖TCP，TCP层队头阻塞未解决。

---

### **4. HTTP/3.0（2022年，基于QUIC）**
- **核心改进**：  
  - **QUIC协议替代TCP**：基于UDP，内置加密（TLS 1.3），减少握手延迟（0-RTT/1-RTT）。  
  - **解决TCP队头阻塞**：每个请求流独立传输，丢包不影响其他流。  
  - **连接迁移**：网络切换（如WiFi→4G）时无需重建连接。  
  - **前向纠错（FEC）**：冗余数据包减少重传延迟。  

**优势**：更低延迟、更强抗丢包能力，适合移动网络。

---

### **对比总结表**
| **版本** | **传输层** | **核心特性**                          | **主要问题**               |
| -------- | ---------- | ------------------------------------- | -------------------------- |
| HTTP/1.0 | TCP        | 基础请求/响应、简单缓存               | 短连接、高延迟             |
| HTTP/1.1 | TCP        | 持久连接、管道化、Host头、精细缓存    | 队头阻塞、头部冗余         |
| HTTP/2.0 | TCP        | 二进制分帧、多路复用、HPACK压缩       | TCP层队头阻塞              |
| HTTP/3.0 | QUIC(UDP)  | 零RTT、流独立传输、连接迁移、内置加密 | 兼容性需提升（逐步普及中） |



# TCP面试题

## 1、TCP如何保证传输可靠性，如果收到了重复数据怎么办？

TCP（传输控制协议）通过以下机制来保证传输的可靠性：

1. 序列号和确认应答：每个 TCP 数据包都有一个唯一的序列号，用于指示数据在传输中的顺序。接收方会发送确认应答（ACK）来确认已经成功接收到的数据，并告知发送方下一次期望接收的数据的序列号。
2. 超时重传：发送方会设置一个定时器，在发送数据后等待一段时间，如果在超时时间内未收到对应的 ACK 确认，发送方会重新发送该数据。
3. 滑动窗口：TCP 使用滑动窗口机制来控制发送方发送数据的速率。接收方会告知发送方它的接收窗口大小，发送方根据接收窗口的大小进行发送，确保不会发送过多的数据，避免接收方无法处理。
4. 丢失数据的检测和重传：如果接收方发现收到的数据包有缺失，它会发送一个特殊的 ACK，告知发送方需要重传缺失的数据。

当收到重复的数据时，TCP 会采取以下操作：

1. 接收方会检测到接收到了重复的数据，但不会将其交给上层应用程序。它会正常发送一个 ACK 确认，通知发送方已经接收到了这些重复数据。
2. 发送方在收到 ACK 确认后，发现这个 ACK 确认的序列号大于当前未被确认的最大序列号，说明之前发送的数据包中有丢失的部分。发送方会根据收到的 ACK 确认来进行重传，确保丢失的数据能够被接收方正确接收。

通过以上的机制，TCP 可以有效地保证传输的可靠性，并能够应对重复数据的情况。

## 2、三次握手和四次挥手

![三次握手](/Users/apple/codebase/lib/Tartarnus/interview/850de5c566ae60989f45cff4b1aad94c.png)

1. **三次握手：** 

   第一次握手 TCP客户进程也是先创建传输控制块TCB，然后向服务器发出连接请求报文，这是报文首部中的同部位SYN=1，同时选择一个初始序列号 seq=x ，此时，TCP客户端进程进入了 SYN-SENT 同步已发送状态

   第二次握手 TCP服务器收到请求报文后，如果同意连接，则会向客户端发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是ack=x+1，同时也要为自己初始化一个序列号 seq=y，此时，TCP服务器进程进入了 SYN-RCVD 同步收到状态

   第三次握手 TCP客户端收到确认后，还要向服务器给出确认。确认报文的ACK=1，ack=y+1，自己的序列号seq=x+1，此时，TCP连接建立，客户端进入ESTABLISHED已建立连接状态 触发三次握手
   

   - **详细流程**：

     ```
     客户端 → SYN=1, seq=x → 服务端  
     服务端 → SYN=1, ACK=1, seq=y, ack=x+1 → 客户端  
     客户端 → ACK=1, seq=x+1, ack=y+1 → 服务端  
     ```

   - **核心问题**：

     - 为什么需要三次握手？
       - **防历史连接**：避免失效的SYN占用资源（如客户端重发SYN后，旧SYN到达服务端）。
       - **同步初始序列号（ISN）**：双向确认序列号，防止数据混淆。
     - 两次握手会有什么问题？
       - 无法防止重复SYN，且服务端无法确认客户端已收到自己的SYN+ACK。

   ![四次挥手](Tartarnus/interview/0dc25c2e6ae3de02cc4039553165d8cf.png)

2. **四次挥手：** 

   第一次挥手 客户端发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态

   第二次挥手 服务器端接收到连接释放报文后，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT 关闭等待状态

   第三次挥手 客户端接收到服务器端的确认请求后，客户端就会进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文，服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。

   第四次挥手 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态，但此时TCP连接还未终止，必须要经过2MSL后（最长报文寿命），当客户端撤销相应的TCB后，客户端才会进入CLOSED关闭状态，服务器端接收到确认报文后，会立即进入CLOSED关闭状态，到这里TCP连接就断开了，四次挥手完成

   

   **为什么客户端要等待2MSL？**
   主要原因是为了保证客户端发送那个的第一个ACK报文能到到服务器，因为这个ACK报文可能丢失，并且2MSL是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃，这样新的连接中不会出现旧连接的请求报文。
   
   - **详细流程**：
   
     ```
     主动方 → FIN=1, seq=u → 被动方  
     被动方 → ACK=1, ack=u+1 → 主动方  
     （被动方处理完数据后）  
     被动方 → FIN=1, seq=v, ack=u+1 → 主动方  
     主动方 → ACK=1, seq=u+1, ack=v+1 → 被动方  
     ```
   
   - **核心问题**：
   
     - 为什么需要TIME_WAIT？默认多久？
       - **等待残留报文**：确保最后一个ACK到达被动方，避免新连接收到旧数据（2MSL，默认60s）。
       - **确保可靠终止**：若ACK丢失，被动方重发FIN时可响应。
     - 大量TIME_WAIT如何优化？
       - `net.ipv4.tcp_tw_reuse`（复用TIME_WAIT端口）、负载均衡器改用长连接。
   
   ![img](Tartarnus/image/通用面试题.images/c41076e52f07374fbd218551b5dfd60a.png)

## 3、TCP与UDP区别

TCP（Transmission Control Protocol）和UDP（User Datagram Protocol）是网络通信中两种常用的传输协议，它们之间的主要区别如下：

1. 连接性：TCP是一种面向连接的协议，通过三次握手建立可靠的连接，确保数据传输的可靠性。UDP是无连接的协议，不需要事先建立连接，发送数据时也不会收到对方是否接收成功的确认。
2. 可靠性：TCP提供可靠的数据传输，通过序号、确认和重传机制来保证数据的完整性和正确性。UDP不提供可靠性保证，发送的数据包可能丢失、重复或者乱序。
3. 传输效率：由于TCP保证了可靠性，所以在传输过程中会有较多的额外开销，如序号管理、确认机制、重传等，因此在传输效率上相对较低。而UDP没有这些额外开销，传输效率较高。
4. 数据包大小：TCP可以处理任意大小的数据，将较大的数据拆分成适合网络传输的小数据段进行传输。UDP每个数据包的大小限制在64KB内。
5. 顺序保证：TCP能够保证数据包按照发送的顺序进行接收和传送，而UDP不能保证数据包的顺序性。
6. 适用场景：TCP适用于对数据可靠性要求较高的应用，如文件传输、电子邮件等。UDP适用于实时性要求较高的应用，如实时视频、音频通信等。

**TCP提供可靠的连接和数据传输，适用于对数据可靠性要求较高的应用场景；UDP是一种简单、快速的传输协议，适用于实时性要求较高的应用场景。选择使用TCP还是UDP需要根据具体的应用需求来决定。**

### 4.1、什么是TCP？什么是UDP？

**TCP**：TCP是一种面向连接的协议，它提供可靠的、有序的、基于字节流的数据传输。它通过三次握手建立连接，在发送方和接收方之间创建一个虚拟的连接通道。TCP协议保证数据的可靠性，它使用流量控制、拥塞控制和错误校验等机制来确保数据的正确到达。TCP适用于对数据准确性和顺序性要求较高的应用，例如文件传输、电子邮件、网页浏览等。

**UDP**：UDP是一种无连接的协议，它提供不可靠的、无序的数据传输。UDP不需要事先建立连接，数据包可以直接从发送方发送到接收方。UDP协议不提供像TCP那样的可靠性保证，因此数据包可能会丢失、重复、乱序。UDP适用于实时性要求高的应用，例如音频流、视频流、在线游戏等，因为它更加轻量级，延迟较低。

### 4.2、如何让UDP变得可靠？

- 一个是重传机制，丢包需要进行重传，可以用ACK也可以用NACK的方式；
- 第二是重排机制，我们在收到乱序数据一定需要增加一个缓冲区进行数据重排；
- 第三是超时机制，长时间没收收到对方的回复需要进行重试；
- 第四，流量控制，在局域网内一般是不考虑这部分，实现起来比较复杂，收益不是那么大。

## **4、如何实现tcp的流量控制？**

TCP（传输控制协议）使用了一种称为滑动窗口的机制来实现流量控制。滑动窗口的目的是确保发送方不会发送过多的数据，以使接收方能够处理和接收这些数据。

以下是 TCP 流量控制的基本原理：

1. 窗口大小（Window Size）：TCP 在连接建立时使用窗口大小进行初始化，表示接收方在没有确认之前可以接收的最大数据量。窗口大小是一个动态的值，接收方可以通过 TCP 协议中的窗口更新信息告知发送方窗口大小的变化。
2. 滑动窗口机制：发送方根据接收方返回的窗口大小信息来决定发送的数据量。发送方发送的数据不能超过接收方的窗口大小，以确保接收方有足够的缓冲区来接收和处理数据。
3. 窗口滑动：接收方将已成功接收并处理的数据确认返回给发送方。发送方根据接收到的确认信息，移动发送窗口的起始位置，允许发送更多的数据。这样，发送方可以根据接收方的处理能力进行调整，避免发送过多的数据导致接收方溢出或拥塞。

## 5、TCP怎么保证传输过程的可靠性？

| **机制**        | **作用**                                |
| :-------------- | :-------------------------------------- |
| 确认应答（ACK） | 确保数据到达接收方，未收到ACK则重传。   |
| 超时重传        | 动态计算RTO，超时未确认则重传。         |
| 序列号与排序    | 标识数据顺序，解决乱序问题。            |
| 滑动窗口        | 流量控制，防止接收方过载。              |
| 拥塞控制        | 避免网络拥塞，动态调整发送速率。        |
| 快速重传/恢复   | 通过重复ACK快速检测丢包，减少等待时间。 |
| 连接管理        | 握手和挥手确保通信双方状态一致。        |
| 校验和          | 检测数据损坏，保证完整性。              |

### **1. 确认应答（ACK）机制**

- **每个数据包必须被确认**：
  - 接收方收到数据后，会发送**ACK（确认应答）**，包含**下一个期望的序列号**（如ACK=1001表示已收到1~1000字节）。
  - 发送方若未收到ACK，会触发重传。
- **累积确认**：
  - ACK号表示**所有之前的数据已正确接收**（例如ACK=3001意味着1~3000字节全部送达）。

------

### **2. 超时重传（Retransmission）**

- **动态计算超时时间（RTO）**：
  - 基于RTT（往返时间）动态调整超时阈值（初始通常为1秒）。
  - 若超时未收到ACK，发送方重传数据。
- **指数退避**：
  - 每次重传后，RTO翻倍（如1s → 2s → 4s），避免网络拥塞加剧。

**1. RTT（Round-Trip Time，往返时间）**

- **定义**：数据包从发送端发出到收到接收端确认（ACK）的总耗时。

- **测量方法**：

  - **采样RTT**：每次发送数据包到收到ACK的时间差（实际测量值）。

  - **平滑RTT（SRTT）**：对历史RTT加权平均，避免瞬时波动干扰。

    ```
    SRTT = α × SRTT + (1-α) × 采样RTT  （α通常取0.8~0.9）
    ```

- **作用**：

  - 衡量网络延迟，直接影响RTO的计算。
  - 影响拥塞控制算法的行为（如BBR依赖RTT测量带宽）。

------

**2. RTO（Retransmission Timeout，超时重传时间）**

- **定义**：发送端等待ACK的超时时间，超过此时间未收到ACK则触发重传。

- **计算公式**（经典Jacobson算法）：

  ```
  RTO = SRTT + 4 × RTTVAR  
  （RTTVAR为RTT的偏差，类似标准差）
  ```

- **动态调整**：

  - **初始值**：通常为1秒（Linux默认）。
  - **上限**：避免无限增长（如Linux限制为120秒）。
  - **退避机制**：超时后指数退避（如首次1秒，第二次2秒，第三次4秒）。

#### **关键问题与场景分析**

##### **Q1：RTT突然增大对RTO的影响？**

- **现象**：网络拥塞导致RTT升高 → RTO随之增大。
- **风险**：若RTO增长过慢，可能延迟重传，降低吞吐量。
- **优化**：现代算法（如Linux的`tcp_rtt_estimator`）会快速响应RTT变化。

##### **Q2：低RTT网络下RTO设置过大的问题？**

- **问题**：RTO默认最小值（如200ms）仍可能在高频交易等场景引入延迟。

- **解决**：调整内核参数：

  ```
  sysctl -w net.ipv4.tcp_rto_min=50ms  # 降低最小RTO
  ```

##### **Q3：重传机制与RTO的关系？**

- **快速重传**：收到3个重复ACK时立即重传（不等待RTO）。
- **超时重传**：RTO触发，表明网络可能严重拥塞（进入慢启动）。

------

### **3. 序列号（Sequence Number）和排序**

- **每个字节唯一编号**：
  - 发送方为每个数据包的**第一个字节**分配序列号（如Seq=0，数据长度1000，则下一包Seq=1000）。
- **接收方重组数据**：
  - 根据序列号对乱序数据包排序，确保应用层收到有序数据。

------

### **4. 流量控制（滑动窗口）**

- **接收方控制发送速率**：
  - 通过ACK包中的**窗口大小（Window Size）**字段告知发送方剩余缓冲区容量。
  - 发送方根据窗口大小调整发送速率，避免接收方缓冲区溢出。
- **零窗口探测**：
  - 若接收方窗口为0，发送方定期发送探测包，直到窗口恢复。

------

### **5. 拥塞控制（Congestion Control）**

- **动态调整发送速率**：
  - 通过**慢启动（Slow Start）**、**拥塞避免（Congestion Avoidance）**、**快速重传（Fast Retransmit）**等算法避免网络过载。
  - 核心参数：
    - **拥塞窗口（cwnd）**：限制未确认数据的最大量。
    - **慢启动阈值（ssthresh）**：触发拥塞避免的窗口大小。

#### **1. 慢启动（Slow Start）**

**目的**‌：在连接初期快速探测网络容量，避免初始阶段发送过多数据导致拥塞。
‌**原理**‌：

- 初始拥塞窗口（cwnd）设为1个[MSS](https://www.baidu.com/s?wd=MSS&ie=utf-8&rsv_pq=b2939f1d00ae7a2b&oq=拥塞控制算法&rsv_t=c299OcfQy2Xlv%2BmwF9Ffbu7FHZepeXMX5ZGCLwiDS22GvQYFJZgeFlynDus&rsv_dl=re_dqa_generate&sa=re_dqa_generate)（最大报文段长度），每收到一个ACK确认，cwnd增加1个MSS。
- 窗口大小呈指数增长（cwnd = cwnd \times 2*c**w**n**d*=*c**w**n**d*×2每轮RTT），直到达到慢启动阈值（ssthresh）或检测到拥塞。
  ‌**特点**‌：虽名为“慢启动”，实际增长迅速，通过指数增长快速适应网络可用带宽。

------

#### **2. 拥塞避免（Congestion Avoidance）**

**目的**‌：在接近网络容量时降低窗口增长速度，避免突发拥塞。
‌**原理**‌：

- 当cwnd ≥ ssthresh时，算法切换为线性增长（每RTT增加1个MSS）。
- 若发生超时重传（RTO），则认为网络拥塞，将ssthresh设为当前cwnd的一半，并重置

------

#### **3. 快速重传（Fast Retransmit）**

‌**目的**‌：减少因丢包导致的等待延迟，快速恢复数据流。
‌**触发条件**‌：发送方连续收到3个重复ACK（如接收方期望序号2却收到3、4、5号报文，均返回ACK=2）。
‌**动作**‌：立即重传丢失报文，无需等待超时计时器。

#### 4.**快速恢复（Fast Recovery）**

‌**目的**‌：避免因单次丢包直接退回到慢启动，维持较高吞吐量。
‌**原理**‌：

- 触发快重传后，将ssthresh设为当前cwnd的一半，cwnd调整为ssthresh + 3（补偿已确认的报文），随后进入拥塞避免阶段。
- 与Tahoe版本（直接重置cwnd=1）不同，Reno等新版本通过快恢复减少性能波动。

------

#### **三阶段交互流程图**

```
慢启动（指数增长）  
  │  
  ▼  
CWND ≥ ssthresh → 拥塞避免（线性增长）  
  │  
  ▼  
丢包事件 → 超时？ → 是 → 慢启动（CWND=1）  
        │  
        ▼  
        否（重复ACK） → 快速重传 → 快速恢复  
```

------

### **6. 快速重传与快速恢复**

- **3次重复ACK触发快速重传**：
  - 若发送方收到**3个相同的ACK**（如连续收到ACK=1001），说明数据包可能丢失，立即重传而不等待超时。
- **快速恢复**：
  - 重传后，拥塞窗口减半（而非重置为1），保持较高传输效率。

------

### **7. 连接管理与可靠性**

- **三次握手建立连接**：
  - 确保双方准备好通信（交换初始序列号，同步窗口参数）。
- **四次挥手释放连接**：
  - 确保数据全部传输完毕，避免残留数据丢失。

------

### **8. 校验和（Checksum）**

- **数据完整性验证**：
  - TCP头部和数据部分计算校验和，若校验失败则丢弃包（触发重传）。

## 6、TCP的性能瓶颈和调优

#### **性能瓶颈**

1. **延迟与带宽限制**：受 RTT（往返时间）和带宽延迟积（BDP）制约。
2. **丢包重传**：丢包触发拥塞控制（如 Cubic/Reno），降低吞吐。
3. **缓冲区限制**：过小的 `rwnd`（接收窗口）或 `cwnd`（拥塞窗口）限制并发数据量。
4. **队头阻塞（HOL）**：单个丢包阻塞整个连接（尤其在 HTTP/2 多路复用时）。

#### **调优方法**

1. **增大缓冲区**：调整 `net.ipv4.tcp_rmem`/`wmem` 和 `net.core.rmem_max`。
2. **启用 SACK/BBR**：减少重传（SACK）或优化拥塞控制（BBR）。
3. **减少延迟**：启用 `tcp_fastopen`（TFO）、调优 `tcp_slow_start_after_idle`。
4. **多路径/多连接**：使用 MPTCP 或连接池分摊负载。

**适用场景**：高带宽长距离网络（如跨数据中心）需针对性优化。



**性能问题**

**延迟与带宽利用率**
TCP的流量控制和拥塞控制机制可能导致传输延迟的增加。特别是在高延迟、低带宽的网络环境中，TCP的性能瓶颈尤为明显。此外，TCP在传输大数据量时，可能会因为频繁的窗口更新和确认机制而降低带宽利用率。

**连接建立与关闭的开销**
TCP连接建立（三次握手）和关闭（四次挥手）过程带来了额外的延迟和开销。在需要大量短连接的应用场景中，这种开销可能成为性能瓶颈。

**数据传输的粒度**
TCP是基于字节流的传输协议，其传输粒度较细。在传输大块数据时，TCP需要将数据分割成多个小数据包进行传输，这增加了传输过程中的处理开销和延迟。

**头阻塞问题**
TCP的滑动窗口机制虽然实现了流量控制，但也可能导致头阻塞问题。当某个数据包因为某种原因被延迟时，其后续的数据包也会因为窗口的限制而被阻塞，从而降低了传输效率。

**优化建议**

**调整TCP参数**
窗口大小：根据网络环境和应用需求，适当调整TCP的接收窗口和发送窗口大小，以提高带宽利用率和降低延迟。
超时重传时间：根据网络延迟和抖动情况，调整TCP的超时重传时间，以减少不必要的重传和延迟。
拥塞控制算法：考虑使用更先进的拥塞控制算法（如CUBIC、BBR等），以提高网络传输的效率和稳定性。
**减少连接开销**
连接复用：在可能的情况下，使用TCP连接复用技术（如HTTP/1.1的持久连接、HTTP/2的多路复用等），以减少连接建立和关闭的开销。
连接池：在应用层实现TCP连接池，以复用现有的连接，减少连接建立和关闭的频率。
**优化数据传输**
数据分段与合并：根据应用需求和网络条件，合理设置数据分段的大小，以减少传输过程中的处理开销和延迟。对于大块数据的传输，可以考虑使用应用层的分段和合并策略。
管道化传输：利用TCP的管道化传输特性，允许在确认前一个数据包之前发送多个数据包，以提高传输效率。
**解决头阻塞问题**
使用TCP分段卸载：在网络设备或操作系统中实现TCP分段卸载功能，以减少主机CPU在处理TCP分段时的开销。
应用层优化：在应用层实现更灵活的数据传输策略，如使用UDP协议进行数据传输（但需注意可靠性和完整性问题），或利用TCP的紧急数据机制来优先传输关键数据。
**利用新技术**
QUIC协议：考虑使用QUIC（Quick UDP Internet Connections）协议，它结合了TCP的可靠性和UDP的低延迟特性，为Web应用提供了更好的传输性能。
SDN与NFV：利用软件定义网络（SDN）和网络功能虚拟化（NFV）技术，实现网络资源的灵活配置和优化，以提高TCP传输的性能和效率。

## 7、tcp 大量time_wait的原因和解决方案

### 原因

在高并发场景下，端口产生大量tcp短连接把**所有可用端口都占完了（TCP端口数量上限是65535）而且还未被系统回收，就会出现无法向服务端创建新的socket连接的情况**，此时系统几乎停转，任何链接都不能建立：`address already in use : connect `异常

### 解决方案

##### **方案 1：内核参数调优（推荐）**

| **参数**                      | **作用**                                | **推荐值**   | **注意事项**                        |
| :---------------------------- | :-------------------------------------- | :----------- | :---------------------------------- |
| `net.ipv4.tcp_tw_reuse`       | 允许复用 `TIME_WAIT` 连接（作为客户端） | `1`          | 仅适用于 **出向连接**（客户端）     |
| `net.ipv4.tcp_tw_recycle`     | 快速回收 `TIME_WAIT`（已废弃）          | **不要启用** | 导致 NAT 环境下连接失败（RFC 冲突） |
| `net.ipv4.tcp_max_tw_buckets` | 限制 `TIME_WAIT` 连接总数               | `100000`     | 超出后直接关闭新 `TIME_WAIT`        |
| `net.ipv4.tcp_fin_timeout`    | 调整 FIN 超时时间（非标准 MSL）         | `30`（秒）   | 需谨慎，可能影响跨网络通信          |

**配置方法**：

```
echo "net.ipv4.tcp_tw_reuse=1" >> /etc/sysctl.conf
echo "net.ipv4.tcp_max_tw_buckets=100000" >> /etc/sysctl.conf
sysctl -p
```

##### **方案 2：应用层优化**

- **使用长连接**：

  - HTTP/1.1 启用 `Keep-Alive`，数据库连接池复用连接。

- **负载均衡器配置**：

  - 反向代理（如 Nginx）开启 `keepalive`：

    ```nginx
    upstream backend {
        server 10.0.0.1:8080;
        keepalive 100;  # 保持 100 个空闲连接
    }
    ```
  
- **连接复用**：

  - 客户端代码设置 `SO_REUSEADDR`：

    ```c
    int opt = 1;
    setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt));
```

##### **方案 3：协议升级**

- **HTTP/2 或 HTTP/3**：
  - HTTP/2 多路复用减少连接数，HTTP/3（QUIC）彻底避免 TCP 握手/挥手。
- **gRPC 替代 REST**：
  - 基于 HTTP/2 的长连接 + 多路复用。

```

## 8、什么是粘包，如何解决粘包？

**粘包问题**是指TCP协议传输中，由于数据流无边界特性，导致接收端可能将多个数据包合并接收的现象。

**原因**：

1. TCP是字节流协议，不维护消息边界
2. 发送端Nagle算法合并小包
3. 接收端缓冲区数据堆积

**解决方案**：

1. **固定长度**：每个包定长（如1024字节），不足补位
2. **分隔符**：用特殊字符（如`\n`）标记包结束
3. **头部声明**：在数据前加长度字段（如4字节头+body）
4. **协议封装**：HTTP/WebSocket等自带边界处理

**推荐实践**：

- 简单场景用分隔符（如Redis协议）
- 高性能场景用头部声明（如gRPC的Length-Prefixed编码）

## 9、什么是分包？

答：TCP分包是**指发送方将应用层数据拆分成多个TCP报文传输的过程**。由于TCP是面向流的协议且MTU限制（通常1500字节），大数据需分多次发送。分包依据：1.MTU限制避免IP分片；2.滑动窗口流量控制；3.拥塞控制算法动态调整。接收方通过序列号重组数据流，保证有序可靠传输。典型场景如：发送3K数据可能被分成3个1K的TCP报文。

## 10、tcp的ack默认是accumulate的还是selectitve的？

**答：**TCP 的 **ACK（Acknowledgment）** 确认机制是 **累积确认（Cumulative ACK）**，而不是选择性确认（Selective ACK，SACK）**默认行为**。但现代 TCP 实现通常支持 **SACK（选择性确认）** 作为可选扩展。



### **1. 默认机制：累积确认（Cumulative ACK）**

- **原理**：
  - 接收方返回的 **ACK 号表示“已连续接收到的最大字节序号+1”**。
  - 例如：
    - 发送方发送：`Seq=1,100`、`Seq=101,200`、`Seq=201,300`。
    - 接收方收到 `1-100` 和 `201-300`（`101-200` 丢失）。
    - **默认 ACK 行为**：只能返回 `ACK=101`（表示期望收到 `101` 开始的数据），无法单独确认 `201-300`。
  - 如果中间有数据丢失，发送方必须重传**整个丢失段及后续数据**（即使后续数据已正确接收）。
- **优点**：
  - 实现简单，兼容性高（所有 TCP 实现都支持）。
- **缺点**：
  - 网络丢包时效率低（可能触发不必要的重传）。

### **2. 选择性确认（SACK，Selective ACK）**

- **原理**：
  - 在 TCP 选项字段中启用 **SACK**，允许接收方**明确告知发送方哪些数据块已收到**。
  - 例如：
    - 发送方发送：`Seq=1,100`、`Seq=101,200`、`Seq=201,300`。
    - 接收方收到 `1-100` 和 `201-300`（`101-200` 丢失）。
    - **SACK 行为**：返回 `ACK=101` + `SACK=201-300`，告知发送方“`201-300` 已收到，只需重传 `101-200`”。
  - 需双方支持（在 TCP 三次握手时通过 `SACK permitted` 选项协商）。
- **优点**：
  - 减少不必要的重传，提高网络利用率。
- **缺点**：
  - 需要两端支持（现代操作系统默认启用）。

------

### **3. 如何检查 SACK 支持？**

**Linux 系统**

```bash
# 查看是否启用 SACK
sysctl net.ipv4.tcp_sack
# 输出 1 表示启用，0 表示禁用

# 临时启用/禁用
sysctl -w net.ipv4.tcp_sack=1
```

**Wireshark 抓包验证**

- 在 TCP 三次握手阶段，观察 `Options` 字段是否包含 `SACK permitted`。
- 数据传输阶段，丢包时是否返回 `SACK` 块。

------

### **4. 默认行为总结**

| 机制                    | 默认是否启用     | 特点                                                |
| :---------------------- | :--------------- | :-------------------------------------------------- |
| **累积 ACK**            | ✅ 是             | 所有 TCP 实现均支持，但效率较低。                   |
| **SACK**                | ✅ 是（现代系统） | 需双方支持，减少重传，默认在 Linux/Windows 中启用。 |
| **D-SACK**（重复 SACK） | 可选             | 用于检测虚假重传，需额外配置。                      |

**结论**

- **TCP 默认使用累积确认（Cumulative ACK）**，但现代系统普遍启用 **SACK** 以提高性能。
- **SACK 需要两端支持**，可通过抓包或 `sysctl` 验证是否生效。
- 在丢包率高的网络中，SACK 能显著提升吞吐量，但某些特殊场景可能需要关闭。



# 网络面试题：

## 1、OSI七层模型和TCP四层模型？

### OSI七层模型 (理论参考模型)

1. **物理层(Physical)**
   - 传输原始比特流
   - 定义电气、机械特性
   - 例如：电缆、光纤、网卡
2. **数据链路层(Data Link)**
   - 将比特组装成帧
   - MAC地址寻址
   - 差错检测(CRC)
   - 例如：以太网、PPP
3. **网络层(Network)**
   - 逻辑寻址(IP地址)
   - 路由选择
   - 例如：IP、ICMP
4. **传输层(Transport)**
   - 端到端连接
   - 可靠/不可靠传输
   - 例如：TCP、UDP
5. **会话层(Session)**
   - 建立/管理/终止会话
   - 例如：RPC、NetBIOS
6. **表示层(Presentation)**
   - 数据格式转换
   - 加密/解密
   - 例如：SSL、JPEG
7. **应用层(Application)**
   - 用户接口
   - 例如：HTTP、FTP

### TCP/IP四层模型 (实际应用模型)

1. **网络接口层(Network Access)**
   - 合并了OSI的物理层和数据链路层
   - 例如：以太网、Wi-Fi
2. **网络层(Internet)**
   - 对应OSI网络层
   - 例如：IP、ICMP
3. **传输层(Transport)**
   - 对应OSI传输层
   - 例如：TCP、UDP
4. **应用层(Application)**
   - 合并了OSI的会话层、表示层和应用层
   - 例如：HTTP、DNS、SMTP

## 2、什么是vlan？什么是vxlan？

### 一、VLAN (Virtual Local Area Network)

**1. 基本概念**

VLAN (虚拟局域网) 是一种在二层网络划分广播域的技术，通过逻辑划分而非物理划分网络。

**2. 优缺点**

- ✅ 优点：简单易用，广泛支持，减少广播风暴
- ❌ 限制：仅 4094 个 VLAN，跨三层网络时功能受限

### 二、VXLAN (Virtual Extensible LAN)

**1. 基本概念**

VXLAN 是一种 overlay 网络技术，通过 MAC-in-UDP 封装实现大二层网络扩展。

**2. 核心组件**

| 组件     | 说明                                  |
| :------- | :------------------------------------ |
| VNI      | 类似 VLAN ID，但范围更大 (1-16777215) |
| VTEP     | 执行封装的网络边缘设备                |
| Underlay | 承载 VXLAN 的物理网络                 |

## 3、mac地址和ip地址的区别？

1、MAC地址的长度为48位（6个字节）；而IP地址为32位。2、MAC地址应用在OSI第二层，即数据链路层；IP地址应用于OSI第三层，即网络层。3、MAC地址的分配是基于制造商；IP地址的分配是基于网络拓朴。

## 4、在网络架构中涉及到哪些io模型

1. **BIO (Blocking I/O) 阻塞式 I/O**
   - **特点**：线程在读写操作时会被完全阻塞，直到数据准备好
   - **工作流程**：
     1. 应用线程发起read()系统调用
     2. 内核等待数据就绪
     3. 数据从内核拷贝到用户空间
     4. 线程继续执行
   - **缺点**：每个连接需要独立线程，资源消耗大
2. **NIO (Non-blocking I/O) 非阻塞式 I/O**
   - **特点**：线程立即返回，通过轮询检查数据状态
   - **工作流程**：
     1. 应用线程发起read()，内核立即返回EWOULDBLOCK
     2. 线程不断轮询检查数据是否就绪
     3. 数据就绪后完成拷贝
   - **优点**：单线程可处理多连接
   - **缺点**：轮询消耗CPU资源
3. **I/O 多路复用 (select/poll/epoll)**
   - **特点**：使用单个线程监控多个文件描述符
   - **工作流程**：
     1. 注册多个socket到复用器
     2. 内核通知哪些socket就绪
     3. 只对就绪的socket进行读写
   - **优点**：高效处理大量连接
   - **代表**：select、poll、epoll(kqueue)
4. **AIO (Asynchronous I/O) 异步 I/O**
   - **特点**：内核完成所有操作后通知应用
   - **工作流程**：
     1. 应用发起aio_read()请求
     2. 内核准备数据并完成拷贝
     3. 内核发送信号/回调通知应用
   - **优点**：完全非阻塞，效率最高
   - **缺点**：实现复杂，支持平台有限

**对比总结**

| 模型     | 阻塞点       | 线程要求     | 复杂度 | 适用场景         |
| :------- | :----------- | :----------- | :----- | :--------------- |
| BIO      | 全程阻塞     | 1连接1线程   | 低     | 低并发简单应用   |
| NIO      | 轮询不阻塞   | 单线程多连接 | 中     | 中等并发         |
| 多路复用 | 仅select阻塞 | 单线程多连接 | 高     | 高并发网络服务   |
| AIO      | 完全不阻塞   | 回调处理     | 最高   | 超高并发专业应用 |

## 5、overlay网络

Overlay网络是实现跨主机容器通信的核心技术，其核心原理是通过在现有网络之上构建虚拟网络层，使不同宿主机上的容器能够直接通信。

### **核心工作原理**

1. **封装与隧道技术**
   - 使用**VXLAN**（Virtual Extensible LAN）协议封装原始数据包
   - 在原始L2帧外添加VXLAN头（含VNI标识符）和UDP外层报头
   - 通过UDP端口4789（默认）穿越底层物理网络
2. **关键组件**
   - **VTEP**（VXLAN Tunnel Endpoint）：负责封包/解包，通常由每台宿主机的虚拟网卡实现
   - **控制平面**：维护跨主机的IP-MAC映射（如Docker通过gossip协议同步）
   - **数据平面**：通过Linux内核的`vxlan`模块处理封包

### **核心优势**

| 特性               | 说明                         |
| :----------------- | :--------------------------- |
| **跨主机透明通信** | 容器无需感知底层物理网络拓扑 |
| **隔离性**         | 每个Overlay网络有独立VNI标识 |
| **扩展性**         | 支持16M（2^24）个虚拟网络    |
| **加密支持**       | 可通过IPsec加密隧道流量      |

## 6、Underlay网络

**Underlay网络**指底层物理网络基础设施（如交换机、路由器、光纤等），负责实际的数据传输，为Overlay网络提供物理连接。

#### **核心特点**

1. **物理/硬件依赖**
   - 基于真实网络设备（如TOR交换机、核心路由器）
   - 使用标准协议（BGP、OSPF、VLAN等）
2. **高性能低延迟**
   - 直接硬件转发，无封装开销（对比Overlay的VXLAN）
   - 适用于高性能场景（如HPC、金融交易）
3. **固定拓扑**
   - 网络架构需预先规划，扩展性受限

#### **常见实现方式**

| 方案                 | 说明                         | 适用场景                  |
| :------------------- | :--------------------------- | :------------------------ |
| **传统数据中心网络** | VLAN + 三层路由              | 中小规模固定集群          |
| **IP Fabric**        | Spine-Leaf架构 + BGP动态路由 | 云数据中心（如AWS/Azure） |
| **SR-IOV**           | 网卡直通容器，绕过虚拟化层   | 超低延迟需求（如5G UPF）  |

#### **与Overlay对比**

| 特性       | Underlay               | Overlay                 |
| :--------- | :--------------------- | :---------------------- |
| **性能**   | 高（无封装开销）       | 中（有VXLAN封装开销）   |
| **灵活性** | 低（依赖硬件配置）     | 高（纯软件定义）        |
| **扩展性** | 有限（受物理设备限制） | 极强（支持16M虚拟网络） |

**典型应用**：

- 需要确定性和高性能的场景（如K8s的HostNetwork模式、电信NFV）
- 与Overlay混合部署，兼顾性能与灵活性（如Calico的IPIP模式）

Underlay是云原生网络的基石，但通常需与Overlay协同使用。

## 7、数据帧是怎么一层层解析

答：数据帧的解析是网络协议栈的逐层拆封过程，**自底向上**分为5层处理：

**物理层**

- 网卡接收电信号/光信号，转换为二进制数据帧

**数据链路层**

- 剥离帧头（如以太网头的MAC地址）和帧尾
- 检查MAC地址匹配性，通过ARP协议寻址

**网络层**

- 解析IP头部（源/目的IP、TTL等）
- 根据路由表决定转发或本地处理

**传输层**

- 拆解TCP/UDP头部（端口号、序列号等）
- TCP协议重组乱序报文，保证可靠性

**应用层**

- 根据端口号交给对应应用（如HTTP→Nginx）
- 按应用协议（HTTP/FTP等）解析最终数据

## 8、数据包经过网卡以后操作系统做了哪些事情？

### **NAPI模式（现代驱动主流）**

**1. 硬中断敲门**
网卡收包 → 触发硬中断 → 唤醒驱动处理。

**2. 调度轮询任务**
驱动调用 `napi_schedule()` → 将NAPI实例加入轮询队列 → **关闭网卡硬中断**，防风暴。

**3. 软中断接手**
内核触发 `NET_RX_SOFTIRQ` 软中断 → 在软中断上下文中执行轮询。

**4. 批量收包+GRO合并**
驱动 `poll()` 循环读DMA环 → 调用 `napi_gro_receive()` → **合并小包**为超大包，减协议栈压力。

**5. 直通协议栈**
通过 `netif_receive_skb()` → 数据包直达IP/TCP层 → 无需经传统Backlog队列。

**6. 收工重启中断**
处理达预设`budget`或无包 → `napi_complete()` → **重开网卡中断**，等下次触发。

## 9、dpdk收包流程

1、绑定NIC到用户态驱动，分配大页内存池（减少TLB miss）

2、配置网卡队列，DMA直接写入用户态内存，启动网卡绑定接收队列

3、**轮询**收包，单次调用取多个包（BURST_SIZE优化CPU流水线）

4、转发给其他网卡或服务

**流程：**初始化环境 → 配队列 → 分内存 → 启网卡 → 轮询收包 → 业务处理  

# Nginx面试题

# mysql面试题

## 1、Mysql中事务的四大特性

 原子性（Atomicity）、一致性（Consistent）、隔离性（Isalotion）、持久性(Durable)，简称为ACID。
 **原子性：**事务的原子性操作，对数据的操作要么全部成功，要么全部失败，实现事务的原子性是基于事务的Redo/Undoh机制。
 **一致性：**执行事务的前后状态一致，理解为数据的一致性。
 **隔离性：**事务之间互相隔离，不受影响，与事务的隔离级别有关。
 **持久性：**事务提交之后，事务的状态会被持久化到数据库中。



**实现：**

```
原子性：通过undolog实现。
持久性：通过redolog实现。
隔离性：通过加锁（当前读）&MVCC（快照读）实现。
一致性：通过undolog、redolog、隔离性共同实现。
```



## 2、Redo/Undo机制

 **Redo log:** 可以用来恢复未写入数据库中但是事务已经成功提交的的数据。(某一时刻，我事务已经提交了，刚要写到数据库，结果数据库挂了，这时候数据库重启的时候就会通过Redo log来进行数据的恢复)
 **Undo log:** 用来记录数据被修改前的值，主要用于事务执行失败后进行回滚。



## 3、事务的隔离级别

 1.**读未提交（READ UNCOMMITTED）**、产生脏读问题。
 2**.读提交 （READ COMMITTED）**、解决了脏读的问题，出现了不可重复读，即在一个事务任意时刻读到的数据可能不一样，可能会受到其它事务对数据修改提交后的影响，一般是对于update的操作。
 3.**可重复读 （REPEATABLE READ）**、解决了之前不可重复读和脏读的问题，但是由带来了幻读的问题，幻读一般是针对insert操作。
 4.**串行化 （SERIALIZABLE）**



| 隔离级别 | 脏读 | 不可重复读 | 幻读 | 第一类更新丢失 | 第二类更新丢失 |
| -------- | ---- | ---------- | ---- | -------------- | -------------- |
| 读未提交 | √    | √          | √    | ×              | √              |
| 读提交   | ×    | √          | √    | ×              | √              |
| 可重复读 | ×    | ×          | √    | ×              | ×              |
| 串行化   | ×    | ×          | ×    | ×              | ×              |

## **4、脏读、幻读、不可重复读问题如何定义**

**1、脏读问题：** 开启一个事物A对数据进行了修改，而此次修改并没有提交到数据库中，这时另一个事务B也访问了这个数据，当且读到事务A修改后未提交的数据，叫做脏读。
 **2、不可重复读问题：** 指在一个事务内，多次读同一数据，结果不一样。事务A开启了事务读取了一条数据，未提交事务，这时候，事务B也开启了事务，针对一条数据。
 并修改了这条数据，然后提交了事务，事务A再次读取这条数据的时候，产生了不一致的结果。
**3、幻读问题：** 是指当事务不是独立执行时发生的一种现象，例如第一个事务查询某个范围的数据行。同时，第二个事务新增、修改、删除这个范围的数据，导致结果不一致这个表中的数据，针对范围数据。
 这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。

## 5、脏读、幻读、不可重复读问题如何解决

脏读、幻读和不可重复读是数据库中的并发访问问题，可以通过以下方式进行解决：

1. **脏读（Dirty Read）**： 脏读是指一个事务读取了另一个事务尚未提交的数据，而后者可能会回滚，导致前者读取到了无效的数据。为了解决脏读问题，可以使用事务的隔离级别来控制，**将隔离级别设置为“读已提交”（Read Committed）或更高级别**，确保一个事务只能读取到已经提交的数据。
2. **幻读（Phantom Read）**： 幻读是指一个事务在两次查询之间，另一个事务插入了符合前一次查询条件的新数据，导致前一次查询得到的结果集发生了变化。要解决幻读问题，可以采用两种方法：一种是使用**锁机制**，如**行级锁**或**表级锁**，保证在一个事务执行期间，其他事务不能插入符合条件的新数据；另一种是使用数据库的多版本并发控制（Multi-Version Concurrency Control，**MVCC**），即通过版本号或时间戳来控制事务的隔离，读取到的数据是一致的。
3. **不可重复读（Non-Repeatable Read）**： 不可重复读是指一个事务多次读取同一行数据，但在两次读取之间，另一个事务修改了该行数据，导致第一次读取和第二次读取的结果不一致。为了解决不可重复读问题，可以使用事务的隔离级别来控制，**将隔离级别设置为“可重复读”（Repeatable Read）或更高级别**，确保在一个事务中多次读取同一行数据时，结果保持一致。

另外，为了更好地解决并发访问问题，还可以采用以下策略：

- 使用悲观锁或乐观锁来控制并发操作，保证数据的一致性。
- 合理设计数据表和索引，减少数据访问冲突的可能性。
- 良好的业务逻辑设计，使得事务执行时间尽量短，减少并发访问的冲突机会。
- 合理配置数据库连接池和线程池，控制并发数量，避免资源竞争和阻塞。

综上所述，通过设置事务隔离级别、使用锁机制或MVCC，并结合合理的数据库设计和系统配置，可以有效解决脏读、幻读和不可重复读等并发访问问题。

## 6、Mysql的锁机制

 InnoDB：只有行级别的锁和表级别的锁;

粒度划分：行锁、表锁

用法划分：乐观锁、悲观锁

类型/基本模式：排他锁、共享锁、意向锁、自增锁

算法：间隙锁、记录锁、插入意向锁、临键锁

## 7、乐观锁与悲观锁

**悲观锁：**

每次获取到数据的时候，都会担心数据被修改，所以每次获取数据的时候都会进行加锁，确保在自己使用的过程中数据不会被别人修改，使用完成后进行数据解锁
期间对该数据进行读写的其他线程都会进行等待 
适合**写入**操作比较频繁的场景

细分可分为**行锁**和**表锁**

**乐观锁：**

每次获取数据的时候，都不会担心数据被修改，所以每次获取数据的时候都不会进行加锁。
但是在更新数据的时候需要判断该数据是否被别人修改过。如果数据被其他线程修改，则不进行数据更新；如果没有被修改，则进行数据更新，主要是通过**版本号(mvcc)实现**。
适合**读取**操作比较频繁的场景



## 8、怎么对mysql进行优化？

MySQL 常用30种SQL查询语句优化方法：

1.应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。

2.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。

3.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描。可以在num上设置默认值0，确保表中num列没有null值。

4.尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，可以使用union all。

5.like匹配查询：%放前面会导致索引失效

6.in 和 not in 也要慎用，否则会导致全表扫描，对于连续的数值，能用 between 就不要用 in 了

7.如果在 where 子句中使用参数，也会导致全表扫描。 select id from t where num=@num

可以改为强制查询使用索引，select id from t with(index(索引名)) where num=@num

8.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。

9.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。

10.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使 用，

并且应尽可能的让字段顺序与索引顺序相一致。

11.很多时候用 exists 代替 in 是一个好的选择：

12.索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，

视具体情况而定。一个表的索引数较好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要。

13.尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。

14.避免频繁创建和删除临时表，以减少系统表资源的消耗。

**MySQL优化常用方法：**

**1、选取最适用的字段属性**
表中字段的宽度设得尽可能小：char 的上限为 255 字节（固定占用空间），varchar 的上限 65535 字节（实际占用空间），text 的上限为 65535。
尽量把字段设置为 NOT NULL，执行查询的时候，数据库不用去比较 NULL 值。

**2、使用联合 (UNION) 来代替手动创建的临时表**
把需要使用临时表的两条或更多的 SELECT 查询合并的一个查询中。

**3、使用索引**
查询语句当中包含有 MAX (), MIN () 和 ORDERBY 这些命令的时候，性能提高更为明显。
索引应建立在那些将用于 JOIN, WHERE 判断和 ORDER BY 排序的字段上。尽量不要对数据库中某个含有大量重复的值的字段建立索引。

## 9、mysql索引失效的场景？

1. **对索引列进行函数操作**： 当在查询条件中对索引列进行函数操作时，例如使用`LOWER`、`UPPER`、`DATE`等函数，会导致索引失效。因为在进行函数操作后，索引无法直接匹配到预期的值，而是需要对整个索引进行扫描。
2. **使用`OR`或`NOT`操作符**： 在查询条件中使用`OR`或`NOT`操作符时，可能会导致索引失效。因为这些操作符会导致查询优化器无法确定正确的索引使用方式，从而选择不使用索引，而是进行全表扫描。
3. **LIKE模糊查询以通配符开头**： 当使用LIKE模糊查询时，如果通配符出现在查询模式的开头，例如`LIKE '%keyword'`，索引将无法被利用，因为需要对整个索引进行扫描。
4. **数据列类型不匹配**： 当查询条件和索引列类型不匹配时，索引将失效。比如在索引列是字符串类型，但查询条件是数字类型，或者索引列是整型，但查询条件是字符串类型。
5. **不满足最左匹配原则**： 如果在使用联合索引时，没有按照联合索引的左侧连续字段进行查询，那么索引将无法被利用，从而导致索引失效。
6. **值分布不均匀**： 当索引的值分布不均匀时，会导致索引失效。例如某个列的大部分值都相同，或者某些值的重复度非常高，那么使用该索引可能会导致大量的数据行需要进行回表查询，从而降低性能。
7. **表数据量较小**： 当表中的数据量较小时，使用索引可能不如全表扫描高效，因为索引需要额外的I/O操作。在这种情况下，MySQL可能会选择不使用索引而直接进行全表扫描。

## **10.MyISAM与InnoDB 的区别:**

1.InnoDB支持事务，MyISAM不支持。

2.InnoDB支持外键，MyISAM不支持，

3.InnoDB是簇聚索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的，MyISAM是非簇聚索引，也是用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。

4.InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量，速度很快（不能加有任何WHERE条件）；

5.Innodb不支持全文索引，而MyISAM支持全文索引，在涉及全文索引领域的查询效率上MyISAM速度更快高；PS：5.7以后的InnoDB支持全文索引了.

6.MyISAM表格可以被压缩后进行查询操作.

7.InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁

8.InnoDB表必须有唯一索引（如主键）（用户没有指定的话会自己找/生产一个隐藏列Row_id来充当默认主键），而Myisam可以没有

9.Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI

Innodb：frm是表定义文件，ibd是数据文件

Myisam：frm是表定义文件，myd是数据文件，myi是索引文件

## 11、数据库三范式

第一范式：强调的是列的原子性，即数据库表的每一列都是不可分割的原子数据项。    

第二范式：要求实体的属性完全依赖于主关键字。所谓完全 依赖是指不能存在仅依赖主关键字一部分的属性。    

第三范式：任何非主属性不依赖于其它非主属性。

**数据库三大范式包含：1、第一范式(1NF)；2、第二范式(2NF)；3、第三范式(3NF)。其中，第一范式(1NF)的要求是属性不可分割，，第二范式(2NF)的要求是满足第一范式，且不存在部分依赖；第三范式(3NF)的要求是满足第二范式，且不存在传递依赖。**

## 12、超键、候选键、主键、外键分别是什么？

-    超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。    
-    候选键：是最小超键，即没有冗余元素的超键。    
-    主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。    
-    外键：在一个表中存在的另一个表的主键称此表的外键。

## 13、SQL 约束有哪几种？

1. 主键约束（Primary Key Constraint）：用于定义表中一列或多列的主键。主键的值必须是唯一的且不能为空，用于标识表中的每一行数据。
2. 唯一约束（Unique Constraint）：用于确保一列或多列的值是唯一的。与主键不同的是，唯一约束允许空值。
3. 非空约束（Not Null Constraint）：用于保证一列的值不能为空。非空约束要求该列在插入或更新时必须包含有效的非空值。
4. 外键约束（Foreign Key Constraint）：用于建立表与表之间的关系。外键约束定义了一列或多列与另一个表的主键或唯一键之间的引用关系，用于维护数据的完整性。
5. 检查约束（Check Constraint）：用于定义列的取值范围或满足某个条件的值。通过检查约束，可以限制数据的输入范围，确保符合特定的业务规则。

## 14、mysql索引的底层结构是什么？为什么使用索引查询快？

在 MySQL 中，常用的索引底层结构是**B+树**。

**特点：**

1. 所有数据都存储在叶子节点上，非叶子节点只存储索引键和指向下一层节点的指针。
2. 叶子节点之间通过双向链表连接，这样可以支持范围查询。
3. B+树的高度相对较低，磁盘IO次数少，适用于大规模数据的读取。

### 14.1、B+树为什么快？

**概述：**

1.B+树减少了IO次数，效率更高(B+树的高度相对于B树低) （这里这么理解：-----就是减少了磁盘的访问次数，毕竟内存速度要比磁盘快的多） 

2.B+树查询跟稳定，因为所有数据放在叶子节点 

3.B+树范围查询更好，因为叶子节点指向下一个叶子结点（叶子节点形成双向链表）



**详解：**

1. 高度平衡：B+树是一种自平衡的树结构，在插入和删除操作时会自动进行平衡调整，使得树的高度保持相对稳定。相比于二叉搜索树等其他树结构，B+树的高度通常较小，从根节点到叶子节点的路径长度相对较短，因此查询的时间复杂度也相对较低。
2. 分级索引：B+树的内部节点只存储键值信息而不存储数据本身，数据都存储在叶子节点上。这种分级索引的方式可以大幅减少内部节点的数量，使得每次查询时需要访问的节点数目减少。另外，由于叶子节点形成了一个有序链表，可通过遍历叶子节点来实现范围查询。
3. 顺序访问性能好：由于B+树的叶子节点形成了一个有序链表，通过遍历叶子节点可以实现顺序访问，这对于范围查询和区间扫描非常高效，避免了频繁的磁盘寻址操作。
4. 磁盘预读特性：B+树的节点大小通常设置为磁盘页的大小，这样每次从磁盘读取一个节点时，往往会预读相邻的节点。由于磁盘I/O是相对较慢的操作，通过预读可以提高磁盘访问性能，减少磁盘IO次数。
5. 可调整的阶数：B+树的阶数（即节点的最大子节点数量）可以根据需求进行调整。较大的阶数可以提高树的更新性能，适应频繁的插入和删除操作；较小的阶数则可以节省内存空间，适用于磁盘存储等资源受限的环境

## 15、一个sql查询可以几个索引？复合索引应该按什么顺序建?

mysql中一个查询只能使用一个索引，

**顺序：**

1、已知查询条件中包括的字段顺序，应该按照查询条件中列的顺序建立联合索引。

2、对于复合索引中的多个字段，应该选择区分度最高的字段放在前面。所谓区分度，是指某一字段中不同值的个数占全部记录的比例。区分度高的字段可以更快地缩小查询范围。

3、还可以通过分析查询语句的执行计划，根据复合索引使用情况的统计信息，选择最优的联合索引顺序。

## 16、说一说你对SQL注入的理解 

SQL注入是一种常见的安全漏洞，它发生在应用程序对**用户输入的数据进行不充分或不正确的过滤、转义或验证时**。攻击者通过在用户输入中插入恶意的SQL代码，从而可以绕过应用程序的安全机制，执行未经授权的数据库操作。这可能导致数据泄露、数据损坏、非法访问、拒绝服务等安全问题。

SQL注入的原理是利用应用程序将用户输入作为字符串拼接到SQL查询语句中的方式。如果应用程序没有正确地处理这些输入，并且直接将其传递给数据库引擎执行，攻击者就可以构造恶意输入来改变原始查询的含义，甚至执行额外的恶意操作。

为了**防止SQL注入攻击**，可以采取以下一些措施：

1. 使用参数化查询或**预编译**语句：使用参数化查询（使用占位符）或预编译语句可以确保用户输入不会被解释为SQL代码，而是作为值传递给查询语句。
2. 输入**验证和过滤**：对用户输入进行验证和过滤，确保输入的数据符合预期的格式和类型。例如，对于整数类型的输入，验证输入是否仅包含数字字符。
3. 转义**特殊字符**：对于用户输入的字符串，应该对其中的特殊字符进行转义，以确保这些字符不会被解释为SQL代码。数据库提供了相应的函数或API来进行转义操作。
4. 最小权限原则：数据库用户的权限应当被限制到最小必需的范围。应该避免使用具有过高权限的账户来连接数据库。
5. 定期更新和维护应用程序和数据库：及时升级和修补程序中的漏洞，保持系统的安全性。

综上所述，了解SQL注入的原理并采取适当的防御措施是确保应用程序和数据库安全的重要步骤。

## 17、什么是最左匹配原则？

**最左优先,以最左边的为起点任何连续的索引都能匹配上。**同时遇到范围查询(>、<、between、like)就会停止匹配。

## 18、什么是聚集索引？什么是非聚集索引？

**聚集索引：**索引的逻辑顺序与磁盘上行的物理存储顺序相同

**非聚集索引**：索引的逻辑顺序与磁盘上行的物理存储顺序不同

**区别：**

通过聚集索引可以一次查到需要查找的数据， 而通过非聚集索引第一次只能查到记录对应的主键值 ， 再使用主键的值通过聚集索引查找到需要的数据。

聚集索引一张表只能有**一个**，而非聚集索引一张表可以有**多个**。

## 19、mvcc是什么？

MVCC（Multi-Version Concurrency Control，多版本并发控制）是数据库（如 MySQL InnoDB、PostgreSQL）用来提高并发性能的一种机制，主要解决 **读写冲突**，使 **读操作不阻塞写操作，写操作不阻塞读操作**。

### **核心思想**

- 每个事务看到的数据版本（快照）是 **事务开始时** 的数据状态，而不是当前最新数据。
- 通过 **版本链** 和 **Undo Log（回滚日志）** 实现数据多版本存储。

### **MVCC 如何工作？**

1. **每行数据隐藏两个字段**：
   - `DB_TRX_ID`：最近修改该行数据的事务 ID。
   - `DB_ROLL_PTR`：指向 Undo Log 的指针（用于找到旧版本数据）。
2. **ReadView（读视图）**：
   - 事务在执行 `SELECT` 时会生成一个 `ReadView`，记录当前活跃事务 ID 列表。
   - 通过比较 `DB_TRX_ID` 和 `ReadView` 判断数据是否可见：
     - 如果 `DB_TRX_ID` < 最小活跃事务 ID → **可见**（已提交）。
     - 如果 `DB_TRX_ID` > 最大活跃事务 ID → **不可见**（未来事务修改的）。
     - 如果在活跃事务列表中 → **不可见**（未提交）。
3. **Undo Log（回滚日志）**：
   - 存储数据修改前的版本，用于构建历史版本数据。

### **MVCC 解决了什么问题？**

✅ **读不阻塞写，写不阻塞读**（提高并发性能）。
✅ **避免脏读、不可重复读**（RR 隔离级别下还能避免幻读）。
✅ 减少锁竞争，提高数据库吞吐量。

# redis面试题

## 1、缓存穿透、缓存击穿、缓存雪崩

|          | 缓存穿透                                               | 缓存击穿                                                     | 缓存雪崩                                                     |
| -------- | ------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 描述     | 查询不存在的数据                                       | 某小段时间大量相同查询达到存储层                             | 缓存无法提供服务，大量请求打到存储层                         |
| 可能原因 | 1. 缓存和库中数据被删除 2. 恶意攻击                    | 某些热点数据过期失效                                         | 大量数据过期，或Redis宕机                                    |
| 解决方法 | 1. 缓存空对象，未命中时将空值存入缓存2. 布隆过滤器拦截 | 1. 热点数据永不过期 2. 互斥加锁，多线程访问redis某key无数据时，只有一个线程能去存储层查询并存入redis，然后其它线程再从redis取数据 | 1. 避免数据同时过期，设置过期时间为随机值 2. 降级和熔断，对于非核心请求直接返回预定义信息 3. 构建高可用服务 |

## 2、redis为什么快？

1、单线程处理命令避免上下文切换和线程竞争带来的开销
2、数据存储在内存
3、c语言本身性能高
4、IO多路复用技术，实现高吞吐的网络IO UNIX IO五种模型

## 3、Redis的线程

从 Redis 的 v1.0 到 v6.0 版本之前，Redis 的核心网络模型一直是一个典型的单 Reactor 模型。Redis v6.0 才改造成多线程模式。

Redis的主要瓶颈是内存和网络带宽，而非CPU。6.0引入多线程解决网络IO问题。

### 3.1、版本变更中的多线程

涉及的多线程
Redis 3.0前	1. 持久化：BGSAVE和BGREWRITEAOF会fork子进程进行

### 3.2、异步任务：关闭文件、将缓冲区冲洗到磁盘文件中

Redis 4.0	异步删除键值对的命令：UNLINK（DEL的异步版本）、FLUSHALL ASYNC、FLUSHDB ASYNC（删除选项，整个数据集还是单个数据库）
Redis 6.0	socket读写、请求解析是多线程，但命令执行是单线程（键值对操作，防止线程不安全）

### 3.3、Redis核心为什么使用单线程

1、避免上下文切换
2、避免同步机制带来开销
3、简单可维护

## 4、redis有哪些数据结构

1. **字符串（String）**：用于存储文本或二进制数据。底层结构是**简单动态字符串**（**SDS**）。
2. **哈希表（Hash）**：用于存储键值对集合。底层结构是**哈希表**，通过哈希算法快速定位到对应的键值对。
3. **列表（List）**：用于存储有序的字符串元素集合。底层结构是**双向链表**。
4. **集合（Set）**：用于存储无序的唯一字符串元素集合。底层结构可以是**哈希表**或**有序整数数组**。
5. **有序集合（Sorted Set）**：用于存储有序的唯一成员和对应的分数（score）值。底层结构是**跳跃表**和**哈希表**的组合。
6. **Bitmap**：用于存储位操作相关的数据。底层结构是**字符串**。
7. **HyperLogLog**：用于基数估算（cardinality estimation）的数据结构。底层结构是**字符串**或**稀疏数组**。
8. **地理空间索引（GeoSpatial）**：用于存储地理空间信息的数据结构。底层结构是**跳跃表**和**哈希表**的组合。

### 4.1、SDS

**1、SDS结构体**

```c
struct sdshdr {
    // buf中已使用的长度
    int len;
    // buf中未使用的长度
    int free;
    // 数据空间
    char buf[];
}
```

这个结构体说明了SDS字符串的长度和未使用的空间大小，以及数据本身。这种设计使得我们能够在常数时间内获取字符串的长度。

**2、动态扩容**

假设我们有一个SDS字符串，并且想要在其后添加一些字符。在SDS中，这个操作是这样实现的：

```
sds sdscat(sds s, const char *t) {
    return sdscatlen(s, t, strlen(t));
}
```

`sdscatlen`函数检查SDS字符串的未使用空间是否足够。如果不足，它会重新分配内存，确保有足够的空间存储新的字符。这个过程是透明的，避免了C字符串的缓冲区溢出问题。

**3、二进制安全**

SDS是二进制安全的，这意味着你可以在SDS中存储任何类型的数据，包括二进制数据。例如：

```c
// 创建一个包含图片数据的SDS
sds s = sdsnewlen(my_image_data, my_image_size);
```

**4、性能优化**
SDS通过预分配策略和惰性空间释放策略优化性能：

**预分配策略**：当SDS字符串需要扩展时，除了为要添加的字符分配空间外，还会分配额外的未使用空间。
**惰性空间释放策略**：当SDS字符串缩短时，SDS不会立即释放多余的内存空间，而是保留这些空间作为未使用空间。
这些设计使得SDS在处理大型字符串时性能出色，且内存利用率高。

**5、兼容C字符串**
虽然SDS在很多方面都比C字符串优秀，但它仍然保持了与C字符串的兼容性。例如，SDS字符串的buf数组总是以空字符'\0'结束，这样可以确保任何期望C字符串的函数都可以正确处理SDS。

SDS是Redis强大性能的关键因素之一。它提供的特性使得Redis能够有效地处理各种数据，包括大型数据和二进制数据，同时保持了高性能和内存效率。


## 5、redis大key问题

**什么是大key？：**
value值占用内存较大

**有什么影响：**
网络传输内容大，占用带宽，服务端和客户端的读取耗时增加
可能是热key，频繁读取影响性能
大key用del删除时，会阻塞线程
可能带来分布式系统中的数据倾斜，资源利用率不平衡
在集群中，数据迁移困难（migrate 命令是通过 dump 和 restore 和 del 三个命令组合成原子命令完成，如果是存在 bigkey 的话，可能会因为大 value 的原因导致迁移失败，而且较慢的 migrate 会阻塞 Redis，影响 Redis 服务）
**如何产生：**
一般是因为业务涉及不合理，没有预计value动态增长

一直往value里塞数据，没有删除或者限制机制
数据没有进行分片，将大key变为小key
**如何排查：**
利用redis-cli bigkeys命令，在线扫描（不会阻塞）
利用redis-rdb-toos，离线分析RDB持久化文件，实时性差，但是完全离线对性能无影响
**如何解决：**
删除： 先用scan渐进式查找key，（用keys * 会阻塞）
低于4.0版本，除了string类型，其他类型都可以每次用del删除一部分
高于4.0版本，可以使用unlink直接异步删除
压缩与拆分：
string类型：难以拆分，可以序列化、压缩。但是会增加额外耗时
hash类型 ：字段拆分，将一个对象分为多个部分，读取时可以使用multiget事务读取
list、set类型：可以通过计算分片到不同的集群节点上

## 6、布隆过滤器

### 6.1、什么是布隆过滤器？

布隆过滤器（Bloom Filter）是**一种用于快速判断一个元素是否属于一个集合的概率型数据结构**。

它通过使用一个**位数组**（通常是由二进制位组成），以及多个哈希函数来实现。位数组的长度事先确定，每个位置都初始化为0。对于要加入布隆过滤器的元素，将其经过多个哈希函数的计算，得到多个哈希值，然后将相应的位数组位置设置为1。判断元素是否存在时，同样将元素经过相同的哈希函数计算，检查对应的位数组位置是否都为1。

布隆过滤器具有以下特点：

1. 快速查询：布隆过滤器的查询时间复杂度很低，通常为O(k)，其中k是哈希函数的数量。
2. 空间效率高：布隆过滤器仅需要占用较少的内存空间，位数组的大小相对于集合的大小是可控的。
3. 可能会存在误判：布隆过滤器在判断一个元素不在集合中时，可以保证100%的准确性。但当判断一个元素在集合中时，存在一定的概率出现误判，即将一个不存在的元素误判为存在。
4. 不支持删除操作：布隆过滤器无法删除已插入的元素，因为删除操作会影响其他元素的判断结果。

布隆过滤器常见的应用场景包括缓存击穿、垃圾邮件过滤、URL去重等。通过合理设置位数组大小和哈希函数的数量，并控制误判率，可以在很多实际场景中实现高效的去重和查询功能。

### 6.2、什么时候会用到布隆过滤器？

1. 垃圾邮件过滤：布隆过滤器可以用于快速判断一封邮件是否是垃圾邮件。通过将已知的垃圾邮件地址或特定的邮件特征添加到布隆过滤器中，可以快速过滤掉大量的垃圾邮件，提高过滤效率。
2. 缓存管理：布隆过滤器可以用于缓存管理中，快速判断一个对象是否存在于缓存中。通过将缓存中的关键字或者哈希值添加到布隆过滤器中，可以避免不必要的查询操作，提高缓存的命中率。
3. URL去重：在爬虫系统中，布隆过滤器可以用于URL去重，避免重复抓取相同的URL。通过将已访问的URL添加到布隆过滤器中，可以快速判断一个URL是否已经被抓取过，从而提高爬取效率。
4. 分布式系统中数据同步：在分布式系统中，布隆过滤器可以用于快速判断某个数据是否存在于其他节点中。通过将数据的关键字或哈希值添加到布隆过滤器中，可以快速判断数据是否已被其他节点保存，从而避免不必要的网络通信和数据传输。
5. 数据库查询优化：在某些情况下，布隆过滤器可以用于数据库查询优化。例如，在一个大型用户表中，可以使用布隆过滤器判断某个用户是否存在于表中，如果不存在则可以避免进行具体的数据库查询操作，减轻数据库负载。

### 6.3、布隆过滤器什么时候会误判？怎么解决？

布隆过滤器在某些情况下可能会出现误判，即将一个不存在的元素误认为存在。布隆过滤器的误判主要由以下两个因素引起：

1. **哈希冲突**：当多个元素经过哈希函数计算后得到相同的位数组索引位置时，就会发生哈希冲突。这可能导致不同的元素被映射到相同的位上，从而造成误判。
2. **已存在元素的相似性**：如果要查询的元素与已存在的元素在哈希函数计算后的位数组索引位置有部分重叠或完全重合，就有可能发生误判。

为了减少误判的发生，可以采取以下方法：

1. 使用多个独立的哈希函数：使用多个不同的哈希函数来计算元素的哈希值，并将对应的位数组位置设置为1。这样可以减少哈希冲突的概率，从而降低误判的风险。
2. 选择适当的位数组大小和哈希函数数量：通过根据预期插入元素数量和可接受的误判率，选择合适的位数组大小和哈希函数数量。调整这些参数可以平衡布隆过滤器的性能和误判率。
3. 结合其他数据结构进行验证：由于布隆过滤器无法从误判中恢复，可以将布隆过滤器作为第一层筛选机制，并结合其他数据结构（如哈希表、数据库等）进行进一步验证。这样可以提高查询结果的准确性。

总的来说，布隆过滤器是一种在空间和时间效率上具有优势的数据结构，但它不是完全准确的。通过调整参数、使用多个哈希函数以及结合其他数据结构进行验证，可以降低布隆过滤器的误判率。

## 7、简述一下redis的stream结构？

Redis的Stream（流）是一种高性能、持久化且有序的数据结构，该结构在Redis 5.0及以上版本引入。Stream是一个抽象概念，可以看作是一个日志文件，其中的消息按照发布的顺序进行记录，并且每个消息都有一个唯一的ID。

下面是关于Redis Stream结构的一些重要特点和操作：

1. 消息顺序：Stream中的消息会按照发布的顺序进行存储，新的消息会追加到已有消息的末尾，因此可以保证消息的顺序性。
2. 唯一ID：每个消息都有一个唯一的ID，通过这个ID可以对消息进行查询、删除或者订阅。
3. 持久化：Stream中的消息会被持久化到磁盘，确保消息的可靠性和持久性。
4. 消息组：Stream可以创建多个消费者组（Consumer Group），每个组可以有多个消费者。消息可以被组内的消费者并行消费，每个消费者都可以从不同的位置开始消费消息，而不会相互干扰。
5. 自动消费位移追踪：当消费者组中的消费者消费消息时，Redis会自动追踪每个消费者的消费进度，并将消费位置保存下来。当有新的消息发布时，消费者组会继续消费新的消息，而不会重复消费已经消费过的消息。
6. 消息持有时间：可以设置Stream中消息的最大持有时间，超过这个时间的消息会被自动丢弃。
7. 基本操作：常见的Stream操作包括发布消息、消费消息、查询消息、删除消息等。

Redis的Stream结构提供了一种简单高效的消息队列解决方案，适用于实时数据处理、日志收集、任务分发等场景。通过Stream结构，开发者可以方便地使用Redis来处理和存储流式数据，并支持多个消费者并行消费，实现高吞吐量和低延迟的消息处理。

## 8、rdb和aop

Redis 是一种内存数据库，可以通过持久化机制将数据保存到磁盘上，以实现数据的持久化存储。Redis 提供了两种持久化方式：RDB 和 AOF。

1. RDB（Redis DataBase）持久化：RDB 是一种快照式持久化方式，它会将 Redis 内存中的数据周期性地保存到磁盘上，生成一个二进制文件。RDB 的主要作用是备份和恢复数据，可以定期创建 RDB 快照文件，以防止系统故障或意外断电导致数据丢失。同时，RDB 文件也可以用于迁移数据到其他 Redis 实例。

RDB 持久化的优点是生成的快照文件较小且加载速度快，适合用于灾难恢复和数据迁移。缺点是在故障发生时，可能会有较少的数据丢失。

1. AOF（Append-Only File）持久化：AOF 日志持久化是将每个写操作追加到一个文件中，记录了 Redis 服务器所执行的写命令。AOF 通过追加写入操作的方式，将数据变更记录在磁盘上，保证了数据的完整性和持久性。

AOF 持久化的主要作用是确保系统故障时最小化数据丢失，并保证数据的完整性。由于 AOF 文件记录了所有写操作，因此在重启 Redis 时，可以根据 AOF 文件的内容重新构建内存中的数据库。AOF 持久化相对于 RDB 来说，数据更加安全、可靠。

需要注意的是，RDB 和 AOF 是可以同时使用的，也可以根据实际需求选择其中一种持久化方式。当两者同时开启时，Redis 会优先使用 AOF 文件来进行数据恢复，因为 AOF 包含了更准确和详细的操作记录。

## 9、redis内存淘汰机制？

Redis 的内存淘汰机制是指当 Redis 内存使用达到上限时，需要对一些已缓存的数据进行淘汰，以留出更多的空间。Redis 提供了多种内存淘汰策略，包括：

1.noeviction（**默认策略**）： 不会删除任何数据，拒绝所有写入操作并返回客户端错误消息（error）OOM command not allowed when used memory，此时 Redis 只响应删和读操作；

2.allkeys-lru： 从所有 key 中使用 LRU 算法进行淘汰（LRU 算法：**最近最少使用算法**）；

3.allkeys-lfu： 从所有 key 中使用 LFU 算法进行淘汰（LFU 算法：**最不常用算法，根据使用频率计算**，4.0 版本新增）；

4.volatile-lru： 从设置了过期时间的 key 中使用 LRU 算法进行淘汰；

5.volatile-lfu： 从设置了过期时间的 key 中使用 LFU 算法进行淘汰；

6.allkeys-random： 从所有 key 中随机淘汰数据；

7.volatile-random： 从设置了过期时间的 key 中随机淘汰数据；

8.volatile-ttl： 在设置了过期时间的key中，淘汰过期时间剩余最短的。

**注意：** 当使用 **volatile-lru、volatile-lfu、volatile-random、volatile-ttl 这四种淘汰策略**时，如果没有 key 可以淘汰，则和 neoviction 一样返回错误。

以上淘汰策略通过在 Redis 配置文件中设置 `maxmemory-policy` 参数来实现。可以根据实际需求选择合适的淘汰策略，来控制 Redis 的内存使用情况。要注意的是，在使用 LRU 策略时，Redis 会维护所有键的访问时间，因此会占用一定的内存资源。

此外，Redis 还提供了手动释放内存的方式，例如通过执行 `DEL` 命令删除某个键及其对应的值，或使用 `LPOP`、`RPOP` 等命令删除列表等数据结构中的元素。这些操作可以显式地释放内存，以减少 Redis 内存使用。但要注意的是，对于持久化数据，手动删除键值会导致备份数据不完整，因此需要谨慎使用。

## 10、Redis的几种模式

### **1. 单机模式（Standalone）**

**特点**

- **单节点运行**：所有数据存储在单个 Redis 实例中。
- **无高可用**：节点宕机则服务不可用。
- **简单易用**：适合开发、测试或低负载场景。

**配置示例**

```
redis-server /path/to/redis.conf
```

**适用场景**

- 本地开发环境
- 低并发缓存

------

### **2. 主从复制模式（Master-Slave Replication）**

**特点**

- **一主多从**：主节点（Master）处理写请求，从节点（Slave）异步复制数据。
- **读写分离**：从节点可处理读请求，分担主节点压力。
- **数据冗余**：从节点备份数据，主节点宕机时可手动切换。

**配置示例**

```
# 主节点配置（无需特殊配置）
# 从节点配置（redis.conf）
replicaof <master-ip> <master-port>
```

**优缺点**

| **优点**             | **缺点**                   |
| :------------------- | :------------------------- |
| 读写分离，提升读性能 | 主节点单点故障             |
| 数据备份，防止丢失   | 异步复制可能导致数据不一致 |

**适用场景**

- 读多写少的业务（如电商商品页）
- 需要数据备份但非强一致的场景

------

### **3. 哨兵模式（Sentinel）**

**特点**

- **高可用**：哨兵（Sentinel）监控主从节点，自动故障转移。
- **自动选主**：主节点宕机时，哨兵选举新主并通知客户端。
- **客户端透明**：客户端通过哨兵获取当前主节点地址。

**架构**

```mermaid
graph TD
    Client --> Sentinel1
    Client --> Sentinel2
    Sentinel1 --> Master
    Sentinel2 --> Master
    Master --> Slave1
    Master --> Slave2
```

**配置示例**

```bash
# Sentinel 配置文件（sentinel.conf）
sentinel monitor mymaster 127.0.0.1 6379 2  # 2表示需要2个Sentinel同意才触发故障转移
sentinel down-after-milliseconds mymaster 5000  # 5秒无响应判定为主观下线
```

**优缺点**

| **优点**             | **缺点**               |
| :------------------- | :--------------------- |
| 自动故障转移，高可用 | 故障转移期间短暂不可用 |
| 支持读写分离         | 配置较复杂             |

**适用场景**

- 需要自动容灾的缓存系统
- 中小规模生产环境

------

### **4. 集群模式（Cluster）**

**特点**

- **数据分片**：采用哈希槽（16384个槽）分散数据到多个节点。
- **去中心化**：无单点故障，节点间通过 Gossip 协议通信。
- **高可用**：每个分片可配置主从复制（如 3主3从）。

**架构**

```mermaid
graph TD
    Client --> Node1[Master]
    Client --> Node2[Master]
    Node1 --> Node1-Slave
    Node2 --> Node2-Slave
```

**配置示例**

```
# 启动集群模式
redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 \  
          127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 \  
          --cluster-replicas 1  # 每个主节点配1个从节点
```

**优缺点**

| **优点**                 | **缺点**             |
| :----------------------- | :------------------- |
| 高并发、高扩展性         | 客户端需支持集群协议 |
| 无单点故障，自动故障转移 | 跨节点事务不支持     |

**适用场景**

- 大数据量、高并发场景（如社交网络热数据）

- 需要水平扩展的分布式缓存

  

  ### **模式对比总结**

| **模式** | **数据分片** | **高可用**  | **适用场景**       |
| :------- | :----------- | :---------- | :----------------- |
| 单机模式 | ❌            | ❌           | 开发/测试          |
| 主从复制 | ❌            | ❌（需手动） | 读多写少，数据备份 |
| 哨兵模式 | ❌            | ✅           | 中小规模生产环境   |
| 集群模式 | ✅            | ✅           | 高并发、大数据量   |
| Pub/Sub  | ❌            | ❌           | 实时消息广播       |

------

### **选型建议**

1. **开发测试**：单机模式。
2. **读多写少**：主从复制 + 哨兵。
3. **高并发大数据**：集群模式。
4. **消息队列**：Redis Stream。



# etcd面试题

## 1、etcd节点间如何通信？

在 etcd 集群中，节点间的通信主要通过 **Raft 协议** 和 **gRPC** 实现，分为以下几个核心部分：

------

### 1. **Raft 协议通信**

etcd 使用 Raft 一致性算法保证数据一致性，节点间通过 Raft 进行以下交互：

- **心跳（Heartbeats）**：Leader 节点定期向 Follower 发送心跳（默认每秒 1 次），维持领导权并检测节点存活。
- **日志复制（Log Replication）**：Leader 将客户端写请求（如 `PUT`）封装为 Raft 日志条目，通过 **Raft 消息** 广播给 Followers，要求多数节点（Quorum）确认后才提交。
- **选举（Leader Election）**：当 Leader 失联时，Followers 会发起选举，通过交换 **RequestVote** RPC 投票选出新 Leader。

> **端口**：默认使用 `2380` 端口（通过 `--listen-peer-urls` 配置）。

------

### 2. **gRPC 通信**

节点间通过 gRPC 高效传输数据，包括：

- **Raft 消息**：如日志复制、心跳等，通过 gRPC 流式传输。
- **快照同步（Snapshot）**：落后过多的 Follower 会从 Leader 拉取快照（通过 `snapshot` RPC），加速数据同步。
- **集群配置变更**：如成员增删（`MemberAdd`/`MemberRemove`）通过 gRPC 协调。

------

### 3. **客户端与集群通信**

- **客户端请求**：客户端通过 `2379` 端口（`--listen-client-urls`）与 Leader 交互（如读写请求）。
- **转发机制**：若请求发送到 Follower，Follower 会将其重定向（Redirect）到 Leader。

------

### 4. **关键配置参数**

- **`--initial-advertise-peer-urls`**：其他节点通过此地址访问本节点（如 `http://node1:2380`）。
- **`--advertise-client-urls`**：客户端访问地址（如 `http://node1:2379`）。
- **`--initial-cluster`**：集群初始成员列表（如 `node1=http://node1:2380,node2=http://node2:2380`）。

------

### 5. **安全通信（TLS）**

生产环境建议启用 TLS 加密：

```bash
--cert-file=/path/to/server.crt \
--key-file=/path/to/server.key \
--trusted-ca-file=/path/to/ca.crt \
--peer-cert-file=/path/to/peer.crt \
--peer-key-file=/path/to/peer.key \
--peer-trusted-ca-file=/path/to/peer-ca.crt
```

------

### 6. **网络要求**

- **低延迟**：Raft 对延迟敏感，建议节点间延迟 < 100ms。
- **稳定性**：避免网络分区，否则可能触发频繁选举。

------

### 总结

etcd 节点间通信的核心是 **Raft 协议**（日志复制、选举）和 **gRPC 传输**，通过 `2380` 端口交互，而客户端通过 `2379` 端口与集群通信。配置时需确保网络连通性和安全性（TLS）。

## 2、**Raft 协议中的脑裂（Split-Brain）问题详解**

脑裂（Split-Brain）是分布式系统中经典的故障场景，指集群因网络分区（Network Partition）分裂成多个独立子集群，每个子集群误认为自己是唯一存活的部分，并可能选举出多个 Leader，导致数据不一致。Raft 协议通过一系列机制**严格避免脑裂**，以下是详细分析：

------

### **1. 脑裂是如何发生的？**

**场景示例**

假设一个 5 节点集群（A、B、C、D、E）因网络故障分裂为两部分：

- **分区 1**：A（Leader）、B、C
- **分区 2**：D、E

此时：

1. **分区 1** 仍能维持多数派（3/5），A 继续作为合法 Leader，接受客户端请求。
2. **分区 2** 的 D 和 E 检测不到 Leader 心跳，超时后会发起选举：
   - 但由于它们只有 2 个节点（未达到多数派 3），**无法成功选举出新 Leader**（Raft 的选举规则要求多数票）。
   - D 和 E 会不断重试选举，但永远不会成功。

**关键点**

- Raft 的**“多数派（Quorum）原则”**确保：
  - 任何子集群必须拥有超过半数节点（`> N/2`）才能选举 Leader 或提交日志。
  - 上述例子中，分区 2（2/5）无法满足条件，因此不会产生第二个 Leader。

------

### **2. Raft 如何彻底避免脑裂？**

**机制 1：选举限制（Election Restriction）**

- **只有日志足够新的节点才能成为 Leader**
  Candidate 发起投票时，必须携带自己的最新日志索引和任期号。其他节点会拒绝投票给日志比自身旧的 Candidate。
  - 防止网络分区后旧 Leader 重新加入时“抢权”。

**机制 2：日志提交必须多数派确认**

- **Leader 提交的日志条目必须被多数节点持久化后才能响应客户端**
  - 即使分区 1（A、B、C）的 Leader A 提交日志，分区 2（D、E）也无法覆盖这些日志（因为它们无法形成多数派）。

**机制 3：任期号（Term）严格递增**

- **每个选举周期对应一个唯一的递增 Term**
  - 如果分区 2 的节点尝试选举，它们的 Term 会递增，但无法获得多数票。
  - 当网络恢复后，分区 2 的节点会识别到分区 1 的 Leader 有更高 Term，自动降级为 Follower。

**机制 4：Leader 心跳压制选举**

- **只有当前 Leader 失联（心跳超时）时才会触发选举**
  - 分区 1 的 Leader A 会持续发送心跳，阻止分区 2 的节点发起有效选举。

------

### **3. 特殊场景：偶数节点集群的风险**

**示例：4 节点集群分裂为 2+2**

- 此时两个分区均无法满足多数派（`> 2`），整个集群将**不可用**（无 Leader 可选举）。
- **Raft 的最佳实践：始终使用奇数节点（如 3、5、7）**
  - 这样任何分区最多只能有一个子集群满足多数派（例如 3 节点集群容忍 1 节点故障，分裂为 2+1 时仍可运行）。

------

### **4. 脑裂 vs. 客户端感知**

即使 Raft 协议内部避免了脑裂，客户端仍可能遇到类似问题：

**场景：客户端连接不同分区**

- **分区 1（Leader A）**：客户端写入成功（多数派确认）。
- **分区 2（D、E）**：客户端读取可能返回旧数据（因无 Leader，请求被拒绝或超时）。
- **解决方式**：客户端库应自动重试或检测 Leader 变更。

------

### **5. 对比其他协议（如 Paxos）**

- **Paxos** 允许并发提议（Multi-Paxos），但需额外机制（如 Lease）避免脑裂。
- **Raft** 通过强 Leader 约束简化设计，天然规避脑裂。

------

### **6. 人为误操作导致的“伪脑裂”**

### **错误配置（如错误 `--initial-cluster`）**

如果管理员手动启动两个独立集群（相同的集群 ID 但不同节点列表），它们会各自形成多数派，导致数据分裂。

- **防护措施**：
  - 使用 `--initial-cluster-state=new` 严格初始化集群。
  - 避免手动修改 etcd 数据目录。

------

### **总结**

Raft 通过以下设计**彻底避免脑裂**：

1. **多数派选举和提交**：确保唯一合法 Leader。
2. **日志完整性检查**：防止过时节点篡权。
3. **Term 递增机制**：强制节点识别最新状态。

**脑裂在 Raft 中是一个被解决的问题**，实际生产中更需关注的是网络分区导致的可用性下降（如少数派分区不可用）。

## 3、etcd watch机制

#### **1. 客户端发起 Watch 请求**

- 客户端通过 gRPC 调用 `Watch()` API，指定监听的 key 或 key 前缀（如 `/foo`）。
- 支持参数：
  - `key`：监听的键。
  - `range_end`：监听前缀范围。
  - `start_revision`：从指定版本开始监听（历史事件）。

#### **2. etcd 服务端处理**

1. **记录 Watch 注册**：

   - etcd 在内存中维护一个 `watcherGroup`，记录所有客户端的监听目标。
   - 每个 watcher 被分配一个唯一 ID，并绑定到客户端的 gRPC 流。

2. **事件匹配与推送**：

   - etcd 的写操作（如 `Put`/`Delete`）会生成事件（`Event`），写入存储并广播到匹配的 watcher。

   - **事件结构**：

     go

     复制

     ```
     type Event {
       Type: PUT/DELETE,  // 操作类型
       Kv:   KeyValue,    // 键值对
       PrevKv: KeyValue,  // 旧值（可选）
     }
     ```

#### **3. 事件推送逻辑**

- **实时事件**：
  - 新写入的数据会立即触发事件，通过 gRPC 流推送给客户端。
- **历史事件**：
  - 若客户端指定了 `start_revision`，etcd 会从 BoltDB 中读取历史变更并补发（按版本号顺序）。

#### **4. 客户端处理事件**

- 客户端通过 gRPC 流持续接收 `WatchResponse`，包含：
  - `Events`：变更事件列表。
  - `Revision`：当前 etcd 存储的全局版本号（用于断点续监）。

#### **5. 连接维护**

- **心跳机制**：
  - 客户端与服务端通过 gRPC 的 `KeepAlive` 维持长连接。
  - 若连接断开，客户端需重新发起 Watch 并指定最后收到的 `Revision`（避免漏事件）。

#### **6. 性能优化**

- **事件合并**：
  - 短时间内的多次修改可能合并为一个事件推送（如连续 `Put` 同一 key）。
- **流控**：
  - 服务端限制每个客户端的推送速率，避免洪泛。

------

**关键特点**

1. **有序性**：事件按 `Revision` 严格有序推送。
2. **可靠性**：支持从任意版本断点续监。
3. **高效性**：基于 gRPC 流式传输，减少连接开销。

**示例（命令行）**

```bash
# 监听 /foo 键的变化
etcdctl watch /foo

# 监听前缀 /foo/ 并从版本 1000 开始
etcdctl watch /foo/ --rev=1000
```

**适用场景**

- 服务发现（如 Kubernetes Pod 变更）。
- 配置动态更新。
- 分布式锁状态监听。

## 4、watch大规模数据监听（如百万级 key），如何优化？

### 实现方式

#### **方案 1：基于 Key 前缀的静态分片**

**适用场景**

- key 本身具有明确的分片标识（如 `/shard-1/user1`, `/shard-2/user2`）。

**实现步骤**

1. **定义分片规则**：

   go

   复制

   ```
   shards := []string{"/shard-0/", "/shard-1/", "/shard-2/"} // 按前缀分片
   ```

2. **为每个分片启动独立 Watch**：

   go

   复制

   ```
   for _, prefix := range shards {
       go func(p string) {
           watcher := client.Watch(ctx, p, clientv3.WithPrefix())
           for resp := range watcher {
               processEvents(resp.Events) // 处理分片事件
           }
       }(prefix)
   }
   ```

**优点**

- 实现简单，无需额外协调。

**缺点**

- 分片不均匀时可能负载倾斜。

------

#### **方案 2：基于一致性哈希的动态分片**

**适用场景**

- key 无明确分片标识，需动态均衡负载。

**实现步骤**

1. **定义哈希分片逻辑**：

   ```
   func getShard(key string, numShards int) int {
       return int(fnv32(key) % uint32(numShards))
   }
   ```
   
2. **为每个分片维护独立 Watch**：

   ```
   shardWatchers := make([]clientv3.Watcher, numShards)
   for i := 0; i < numShards; i++ {
       shardWatchers[i] = client.Watch(ctx, "", clientv3.WithPrefix()) // 监听全量 key
   }
   ```
   
3. **客户端过滤事件**：

   ```
   for resp := range shardWatchers[shardID].Chan() {
       for _, ev := range resp.Events {
           if getShard(string(ev.Kv.Key), numShards) == shardID { // 仅处理本分片 key
               processEvent(ev)
           }
       }
   }
   ```

**优点**

- 负载更均衡，适合动态 key 分布。

**缺点**

- 客户端需过滤无关事件（浪费带宽）。

------

#### **方案 3：代理层分片（推荐生产使用）**

```
Client → Proxy（分片逻辑） → etcd Watch Streams
```

**实现步骤**

1. **代理层（如自定义 gRPC 服务）**：
   - 接收客户端监听请求，按分片规则创建多个 etcd Watch 流。
   - 合并多个流的事件，按分片规则返回给客户端。
2. **客户端**：
   - 只需连接代理，无需关心分片细节。

**优点**

- 客户端无感知，分片逻辑可动态调整。
- 代理可集成限流、重试等逻辑。

**缺点**

- 需维护额外代理服务。

------

### **总结**

- **分片 Watch 的核心目标**：解决大规模 key 监听时的性能瓶颈。
- **三种实现方式**：
  - **静态分片**：简单但需预分配。
  - **哈希分片**：均衡但需客户端过滤。
  - **代理分片**：生产级推荐，解耦客户端。
- **关键问题**：
  - 分片均匀性、事件顺序性、容错恢复。

## 5、etcd mvcc机制

### **etcd MVCC 机制核心总结**

------

#### **1. 核心设计目标**

- **多版本并发控制**：支持 key 的历史版本查询与监听，避免读写冲突。
- **全局一致性**：所有修改（包括跨 key）严格按全局 `Revision` 排序。

------

#### **2. 关键数据结构**

| **组件**          | **作用**                                                   |
| :---------------- | :--------------------------------------------------------- |
| **BoltDB**        | 持久化存储 key-value 数据，按 `Revision` 索引。            |
| **全局 Revision** | 单调递增的 64 位整数，每次修改（事务）递增，标识版本顺序。 |
| **KeyIndex**      | 内存中的 B-tree，维护 key 到 `Revision` 的映射，加速查询。 |
| **WatcherGroup**  | 管理所有 Watch 流，将事件推送给匹配的客户端。              |

------

#### **3. 核心机制**

| **机制**               | **说明**                                                     |
| :--------------------- | :----------------------------------------------------------- |
| **数据写入**           | 每次 `Put`/`Delete` 生成新 `Revision`，旧数据保留（除非压缩）。 |
| **数据读取**           | 可指定 `Revision` 读取历史版本（如 `etcdctl get --rev=1000 /key`）。 |
| **事件监听（Watch）**  | 客户端从指定 `Revision` 监听变更，事件严格按 `Revision` 顺序推送。 |
| **压缩（Compaction）** | 定期清理旧 `Revision` 释放空间（手动或自动触发）。           |

------

#### **4. 特点与优势**

| **特性**       | **说明**                                              |
| :------------- | :---------------------------------------------------- |
| **强一致性**   | 所有客户端看到的事件顺序一致（依赖全局 `Revision`）。 |
| **历史查询**   | 支持读取任意历史版本，适合审计、回滚等场景。          |
| **高效 Watch** | 基于 `Revision` 的增量监听，避免轮询。                |
| **分布式协同** | 被 Kubernetes 等系统用于服务发现、配置同步。          |

------

#### **5. 与 MySQL MVCC 对比**

| **维度**     | **etcd MVCC**                    | **MySQL MVCC**           |
| :----------- | :------------------------------- | :----------------------- |
| **版本标识** | 全局 `Revision`（严格有序）      | 事务 ID（仅单机有序）    |
| **存储方式** | 直接存多版本，按 `Revision` 索引 | 通过 Undo Log 回溯旧版本 |
| **监听支持** | 原生 Watch 机制                  | 需依赖 Binlog 或外部工具 |
| **适用场景** | 分布式协同、配置管理             | 事务隔离、OLTP 读写并发  |

------

#### **6. 生产注意事项**

- **压缩策略**：合理设置 `--auto-compaction-retention`（如 `1h`），避免历史数据被意外清理。
- **Watch 性能**：分片监听海量 key 时，避免单 Watch 流缓冲区溢出。
- **Revision 持久化**：客户端需记录最后处理的 `Revision`，实现断点续传。

------

## 6、etcd的事务机制

etcd 的事务机制基于 **CAS（Compare-And-Swap）** 模型，提供原子性、隔离性和一致性的操作，适用于分布式协调场景（如分布式锁、配置更新）。以下是其核心设计和工作流程：

### **1. 事务的基本结构**

etcd 的事务由 **条件判断（Compare）** 和 **操作执行（Then/Else）** 两部分组成：

go

复制

```
Txn {
    Compare: [条件1, 条件2, ...],  // 类似 SQL 的 WHERE
    IfSuccess: [操作1, 操作2, ...],  // 条件成立时执行（Then）
    IfFailure: [操作1, 操作2, ...]   // 条件不成立时执行（Else）
}
```

------

### **2. 事务的执行流程**

**步骤 1：客户端发起事务**

客户端构造一个事务请求，包含多个比较条件和对应的操作：

bash

复制

```
etcdctl txn \
    --compare="value(/key) == 'old-value'" \
    --compare="mod_revision(/key) > 1000" \
    --then="put /key 'new-value'" \
    --else="get /key"
```

**步骤 2：服务端处理**

1. **串行化事务**：
   - etcd 的 Raft 层将事务作为一个日志条目广播，确保所有节点按相同顺序执行。
2. **条件检查**：
   - 在内存中检查所有 `Compare` 条件是否全部成立（原子性）。
3. **执行操作**：
   - 如果条件成立，执行 `IfSuccess` 中的操作；否则执行 `IfFailure`。
4. **返回结果**：
   - 客户端收到成功/失败标志及操作结果。

**步骤 3：提交到存储**

- 事务成功后，修改的数据会写入 MVCC 存储，并分配全局唯一的 `Revision`。

------

### **3. 关键特性**

**(1) 原子性**

- 事务内的所有操作（`Compare` + `Then/Else`）作为一个整体提交或回滚。

- **示例**：转账场景（检查余额 → 扣减 → 增加）

  go

  复制

  ```
  Txn {
      Compare: "value(/account/A) >= 100",
      IfSuccess: [
          "put /account/A 50",  // 扣减 100
          "put /account/B 150"  // 增加 100
      ],
      IfFailure: "get /account/A"
  }
  ```

**(2) 隔离性**

- 事务在 **可串行化隔离级别** 下运行：
  - 读写操作不会看到中间状态。
  - 通过全局 `Revision` 实现快照隔离（Snapshot Isolation）。

**(3) 条件检查支持的类型**

| **条件类型**            | **说明**                  | **示例**                    |
| :---------------------- | :------------------------ | :-------------------------- |
| `value(key) == val`     | 检查 key 的当前值         | `value(/foo) == 'bar'`      |
| `mod_revision(key) > N` | 检查 key 的最后修改版本号 | `mod_revision(/foo) > 1000` |
| `version(key) > N`      | 检查 key 的修改次数       | `version(/foo) > 3`         |
| `key_exists(key)`       | 检查 key 是否存在         | `key_exists(/foo)`          |

------

### **4. 实际应用场景**

**(1) 分布式锁**

```
Txn {
    Compare: "create_revision(/lock) == 0",  // 锁不存在
    IfSuccess: "put /lock holder1",         // 获取锁
    IfFailure: "get /lock"                  // 锁已被占用
}
```

**(2) 乐观并发控制**

```
Txn {
    Compare: "mod_revision(/config) == 123",  // 检查版本未变化
    IfSuccess: "put /config new_value",       // 更新配置
    IfFailure: "get /config"                  // 已被其他客户端修改
}
```

**(3) 条件更新**

```
# 只有 /key 的值为 "old" 时才更新
etcdctl txn \
    --compare="value(/key) == 'old'" \
    --then="put /key 'new'" \
    --else="get /key"
```

------

### **5. 性能与限制**

| **特性**           | **说明**                                                     |
| :----------------- | :----------------------------------------------------------- |
| **吞吐量**         | 事务需通过 Raft 共识，性能低于单 key 操作（约 1000-3000 TPS，依赖集群规模）。 |
| **Key 数量限制**   | 单个事务最多操作 128 个 key（防止过大事务阻塞集群）。        |
| **Watch 事件触发** | 事务成功后会触发 Watch 事件（按 `Revision` 顺序推送）。      |

------

### **6. 与其他系统的对比**

| **系统**  | **事务模型**      | **特点**                          |
| :-------- | :---------------- | :-------------------------------- |
| **etcd**  | CAS + 条件事务    | 强一致性，适合协调类场景          |
| **MySQL** | ACID 事务（行锁） | 适合复杂 SQL，但分布式扩展性差    |
| **Redis** | 单机 Lua 脚本     | 高性能，但无跨 key 的强一致性保证 |

------

### **7. 最佳实践**

1. **避免大事务**：拆分成多个小事务减少阻塞。
2. **合理使用条件**：减少冲突概率（如乐观锁）。
3. **监控压缩**：避免事务依赖的历史版本被清理。

------

### **总结**

etcd 的事务通过 **CAS + 条件判断** 提供分布式环境下的原子操作，适用于锁、配置更新等场景。其核心优势是强一致性和 Watch 集成，但需注意性能限制和压缩影响。

# 容器面试题

## 0.5、什么是云原生？

云原生（Cloud Native）是一种软件架构和开发方法论，旨在让应用程序能够更好地利用云计算的弹性、可扩展性和高可用性等特性。它倡导将应用程序设计为以微服务为基础的分布式系统，并采用容器化部署、动态编排、自动化管理等技术来实现高度可伸缩、弹性可靠的部署和运维。

云原生的核心原则包括：

1. **使用容器化部署**：将应用程序打包为独立的容器，包含应用程序及其依赖，并且可以在不同环境中运行，提供良好的可移植性、隔离性和资源利用率。
2. **以微服务为架构风格**：将应用程序拆分为多个小型、独立、可独立部署和扩展的服务单元，每个服务单元关注某个具体的业务功能，通过轻量级的通信机制组合起来。
3. **动态编排和自动化管理**：使用容器编排工具（如Kubernetes）来自动化管理和编排容器化的应用程序，根据需求自动调整应用程序的规模、部署新的服务实例以及监控和恢复故障。
4. **弹性和可伸缩性**：通过自动化的扩展和收缩机制，根据负载情况调整应用程序的规模，以满足不同的业务需求，提供高度可伸缩性和弹性。
5. **持续交付和DevOps实践**：采用持续集成、持续交付和自动化测试等工程实践，通过自动化流程来构建、部署和更新应用程序，加快交付速度、减少风险。

云原生架构和方法论的目标是提供灵活、高效、可扩展和可靠的应用程序交付和运维方式，使开发人员能够更快地迭代和发布新功能，同时提供用户良好的体验和高可用性。

## 1、容器和虚拟机有什么区别？

虚拟机（Virtual Machine）和容器（Container）是用于虚拟化和隔离应用程序的两种不同的技术。它们之间有以下区别：

1. **虚拟化层级**：虚拟机在硬件和操作系统之间创建了一个完整的虚拟化层，包括虚拟的硬件、操作系统和应用程序。而容器是在操作系统层面上实现的虚拟化技术，多个容器共享同一个操作系统内核。
2. **资源占用**：虚拟机通常需要较大的资源开销，因为每个虚拟机都需要独立的操作系统、内存和硬件模拟等。容器则共享宿主机操作系统的内核，因此资源消耗更低，启动和停止速度更快。
3. **隔离性**：虚拟机提供了更高的隔离性，每个虚拟机都运行在独立的虚拟环境中，相互之间隔离。容器则共享宿主机的操作系统内核，通过命名空间（namespace）和控制组（cgroups）等技术实现进程级别的隔离。
4. **迁移和扩展性**：由于虚拟机包含了完整的操作系统和应用程序，迁移和扩展虚拟机需要更多的操作和资源。而容器可以更轻松地迁移和扩展，容器镜像可在不同的环境中快速部署。
5. **管理和部署**：虚拟机通常需要使用虚拟化管理工具来管理和部署。容器使用容器编排工具（如Docker、Kubernetes）可以更方便地管理和部署大规模的容器应用。

## 2、解释一下 Docker 是什么，它的核心原理是什么？

 Docker 是一种流行的容器化平台，它提供了一个简单而强大的方式来创建、部署和运行容器。Docker 的核心原理是利用 Linux 内核的命名空间（namespace）和控制组（cgroup）功能，实现容器之间的隔离和资源管理。

### 2.1、docker和containerd的区别？

1、Docker 是一个开源的容器运行时平台，提供了一套高级工具和接口，使得容器的创建、部署和管理变得简单和便捷。containerd 是一个轻量化的容器运行时，它负责管理容器的生命周期。

2、containerd不需要经过dockershim，所以调用链更短，docker需要经过所以调用链更长；

3、cni上Docker 使用自己的网络插件模型，称为 "docker0" 网桥，以及一些内置的网络驱动程序。当使用 Docker 创建和管理容器时，Docker 自身会负责调用适当的网络插件来创建和配置容器的网络接口。这些网络插件可以是 Docker 自带的插件，也可以是第三方开发的插件。containerd 使用 CNI 规范作为其网络接口。CNI 是一个独立于容器运行时的插件化网络规范，允许不同的容器运行时使用统一的网络接口。在 containerd 中，当创建和管理容器时，containerd 会调用 CNI 插件来配置容器的网络设置，包括网络连接、IP 地址分配等。CNI 插件通常是以二进制可执行文件的形式提供，根据需要调用适当的插件。

4、Docker 使用自己的容器格式（Docker 镜像），containerd 支持多种容器格式，包括 Docker 格式

**docker镜像和oci镜像有什么区别？**

1. 格式：

- Docker 镜像格式：Docker 使用自己的镜像格式（通常称为 Docker 镜像格式或 Docker 镜像描述符），该格式采用多层文件系统结构，每一层都包含了容器所需的文件和配置信息。Docker 镜像格式还包括额外的元数据和功能，如镜像标签、容器指令等。
- OCI 镜像格式：OCI 规范定义了一个开放的容器镜像格式，称为 OCI 镜像（OCI Image）。OCI 镜像采用了一种与 Docker 不同的格式，它采用单一的 Tar 文件来表示整个镜像，而不再使用多层文件系统结构。OCI 镜像中的文件和配置信息被归档到一个或多个 Tar 文件中。

1. 兼容性：

- Docker 镜像兼容性：Docker 镜像格式是 Docker 自有的格式，因此可以直接在 Docker 容器运行时（如 Docker Engine）中使用。Docker 镜像可以直接通过 Docker 命令进行构建、发布和管理。
- OCI 镜像兼容性：OCI 镜像采用了开放的规范，因此可以在遵循 OCI 规范的容器运行时中使用。这意味着 OCI 镜像可以在许多不同的容器运行时中使用，包括 Docker、containerd 和 CRI-O 等。

1. 生态系统：

- Docker 镜像生态系统：Docker 镜像格式是 Docker 生态系统的核心组成部分，拥有广泛的镜像仓库（如 Docker Hub）和工具链（如 Docker CLI、Compose 等）。Docker 生态系统提供了丰富的功能和社区支持。
- OCI 镜像生态系统：OCI 镜像规范为开放的容器标准化提供了基础，各种容器运行时和工具可以基于这个规范进行开发。OCI 镜像可以与符合 OCI 规范的工具和生态系统集成。

## 3、Kubernetes 是什么？它用于解决什么问题？ 

Kubernetes 是一个开源的容器编排平台，用于自动化容器的部署、扩展和管理。它解决了容器化环境中的服务发现、负载均衡、故障恢复等问题，并提供了强大的编排和调度能力。

## 4、如何将一个应用程序容器化，并编写 Dockerfile？ 

可以通过创建一个 Dockerfile 文件来容器化应用程序。Dockerfile 是一个文本文件，其中包含了一系列的指令，用于构建容器镜像。通过定义基础镜像、复制文件、安装依赖和设置运行命令等步骤，可以将应用程序打包成一个可运行的容器。

## 5、k8s如何实现服务注册和负载均衡

1. 服务注册： 在Kubernetes中，服务通过创建一个抽象的资源对象叫做Service来进行注册。Service定义了一组Pod的逻辑分组，并为这些Pod提供了一个稳定的虚拟IP地址和端口。当Service创建时，它会自动分配一个唯一的DNS名称。其他的Pod或外部服务可以使用这个DNS名称来访问Service。

2. 负载均衡： Kubernetes中的Service会为后端的Pod实例提供负载均衡。当请求到达Service所在的虚拟IP地址时，负载均衡器会将请求转发到后端的Pod实例上。

   a. 集群内部负载均衡：Kubernetes会在每个节点上创建一个iptables规则，将Service的虚拟IP地址映射到后端Pod的真实IP地址，并使用轮询算法进行负载均衡。

   b. 集群外部负载均衡：如果需要将服务暴露给集群外部的客户端，Kubernetes可以通过集成外部负载均衡器来实现。例如，可以使用云服务商提供的负载均衡器（如AWS ELB、GCP Load Balancer）或者独立的Ingress控制器来处理外部流量的转发。

## 6、Ingress和Service有什么区别

1. Service：
   - Service 是 Kubernetes 中的一个内部抽象，为一组 Pod 定义了一个稳定的网络端点。
   - Service 允许 Pod 之间进行通信和负载均衡，在不影响连接性的情况下实现部署的扩展和更新。
   - Service 可以在集群内部（ClusterIP）、对外部客户端（NodePort 或 LoadBalancer）或仅内部使用（Headless）进行公开。
   - Service 在 OSI 模型的第四层（传输层）工作，使用 IP 地址和端口号。
2. Ingress：
   - Ingress 是一个更高级的 API 对象，为集群内的服务提供对外访问。
   - Ingress 充当流量入口，根据 Ingress 资源中指定的主机名、路径或其他规则，将请求从集群外路由到相应的 Service 上。
   - Ingress 允许配置 TLS 终止、虚拟主机和基于 URL 的 HTTP/HTTPS 流量路由。
   - Ingress 在 OSI 模型的第七层（应用层）工作，检查 HTTP/HTTPS 请求并根据规则进行相应的操作。

简而言之，**Service 提供集群内部的网络连接和负载均衡，而 Ingress 提供对集群内部服务的外部访问和高级路由功能。Service 管理内部网络，而 Ingress 管理外部网络入口。**

## 7、容器是如何实现隔离的？隔离了什么？

1. **进程隔离**： 容器使用Linux命名空间（namespaces）技术，将各个容器的进程隔离开，使得每个容器都具有独立的进程空间，从而避免了进程之间的干扰。每个容器都有自己的PID命名空间，使得容器中的进程对于其他容器和主机上的进程是不可见的。
2. **文件系统隔离**： 容器使用Linux的UnionFS（联合文件系统）技术，将底层镜像文件系统与容器私有的写时复制（Copy-on-Write）层相结合。这样每个容器都可以拥有自己的文件系统，但又与主机和其他容器共享基础镜像的文件系统。这样既实现了文件系统的隔离，同时也节省了存储空间。
3. **网络隔离**： 容器使用Linux的网络命名空间技术，为每个容器提供独立的网络栈，包括独立的IP地址、网络接口、路由表等。这样容器之间的网络通信是相互隔离的，可以使用不同的端口和协议。
4. **资源隔离**： 容器可以使用Linux的cgroups（控制组）机制来限制容器对资源的使用，如CPU、内存、磁盘I/O等。这样可以确保容器的资源使用在一定范围内，防止一个容器耗尽主机的资源，影响其他容器的正常运行。

## **8、简述下etcd以及在k8s中的作用**

etcd 是一个可靠、高性能的分布式键值存储系统，提供了强一致性、容错性和简单易用的 API，可以广泛应用于分布式系统中的配置管理、服务发现、分布式锁等场景。

**特点：**

1. 一致性：etcd 使用 Raft 算法来实现分布式一致性，确保在各个节点之间的数据强一致性。Raft 提供了选举、日志复制和安全性的保证，使得 etcd 可以容忍节点故障，提供高可用性。
2. 可靠性：etcd 将数据持久化到磁盘上，即使在节点故障、网络分区或系统重启的情况下，也能保证数据的可靠性和一致性。它使用日志复制机制来保证数据的可恢复性，并支持快速故障转移，确保服务的可用性。
3. 简单的 API：etcd 提供了简单易用的 RESTful API，可以通过 HTTP 或 gRPC 进行访问。应用程序可以使用基本的 CRUD 操作对键值对进行读写操作，也支持一些高级操作如事务和 Watch。
4. 高性能：etcd 使用了内存缓存技术和批量操作优化等策略，提供了很高的读写性能和低延迟。它还支持自动压缩和自动过期等功能，帮助节约存储和提高数据访问效率。
5. 分布式：etcd 可以在多个节点上进行部署，形成一个分布式集群。它使用选举机制选举一个 Leader 节点，负责处理客户端请求和日志复制。其他节点作为 Follower 节点，通过与 Leader 节点保持心跳来保持同步。
6. 可扩展性：etcd 集群可以根据需求进行水平扩展。当需要增加更多节点时，可以简单地添加新节点到现有集群，etcd 会自动进行重新平衡和数据迁移，无需停机或应用程序修改。

**在k8s中的作用**

1. **存储集群状态**：etcd 在 K8s 中被用来存储集群的整体状态信息，包括节点的状态、Pod 的状态、服务和副本控制器的信息等。这些状态信息被保存为键值对的形式，并通过 etcd 的分布式特性来保证高可用性和一致性。
2. **服务发现**：Kubernetes 中的服务发现依赖于 etcd 来存储和维护服务的相关信息。当一个服务被创建时，它的 IP 地址和端口信息会被注册到 etcd 中，其他服务可以通过查询 etcd 获取到这些信息，从而实现服务之间的通信。
3. **配置管理**：etcd 也被用于存储和管理应用程序的配置信息。在 Kubernetes 中，ConfigMap 对象用于将配置数据存储在 etcd 中，应用程序可以通过挂载 ConfigMap 来获取最新的配置信息，当配置发生变化时，应用程序能够自动感知到并更新配置。
4. **调度和容灾**：etcd 的高可用特性使得 K8s 可以在集群中运行多个 etcd 节点，通过选举一个 Leader 提供服务。这样即使某些节点发生故障，集群仍然能够继续正常工作，保证服务的高可用性和容灾能力。
5. **水平扩展**：etcd 的分布式架构使得 K8s 可以轻松地进行水平扩展。当需要增加更多的节点时，可以简单地添加新的 etcd 节点到集群中，数据会自动进行重新平衡和迁移，无需停机或修改应用程序。

### 8.1、etcd是如何保证一致性的？

在Kubernetes（K8s）集群中，多个主节点之间需要保证数据一致性，特别是对于存储集群状态和元数据的ETCD数据存储后端。以下是Kubernetes中实现多个主节点数据一致性的机制：

1. ETCD分布式一致性存储： Kubernetes使用ETCD作为其数据存储后端，用于持久化集群的状态和元数据。ETCD是一个高度可用、分布式且一致性的键值存储系统，它使用Raft一致性算法来确保数据的一致性。ETCD集群通常由多个节点组成，以容忍单个节点或部分节点的故障。
2. 主节点选举： ETCD集群中的所有节点都可以成为主节点候选者，并通过Raft协议进行选举。在选举过程中，节点会相互交换投票并达成共识，选择出一个新的主节点。这样做的目的是确保集群中只有一个活跃的主节点来处理写入操作，从而避免数据的不一致性。
3. 数据复制和同步： ETCD集群中的每个节点都保存有完整的数据副本，通过内部协议和机制实现数据的复制和同步。当写入操作（例如创建、更新或删除）发生时，主节点会将变更记录复制到其他节点，从而保持集群中的数据一致性。每个节点都接收并应用这些变更，以确保数据副本的同步。
4. 容灾备份： 为了进一步增加数据的安全性和可靠性，可以对ETCD数据进行容灾备份。通过定期备份ETCD数据并将其复制到多个位置，即使整个ETCD集群发生故障，也可以使用备份数据来恢复并确保数据的完整性和一致性。

需要注意的是，Kubernetes的主节点只负责控制平面的操作，如调度、资源管理和状态管理等，并不直接处理容器的数据。容器的数据一致性主要由底层存储和持久化卷（Persistent Volume）等机制来保证，而不是由Kubernetes的主节点来负责。因此，在设计应用程序和选择存储方案时，需要考虑底层存储系统的数据一致性和可靠性。

总结起来，通过ETCD的分布式一致性存储、主节点选举、数据复制和同步等机制，Kubernetes可以保证多个主节点之间的数据一致性，以确保集群的稳定和可靠运行。

### 8.2、etcd是如何持久化的？

ETCD使用磁盘持久化来确保数据的安全性和可靠性。当ETCD集群接收到写入操作时，它会将数据持久化到磁盘，以便在发生故障或重启后可以重新加载并恢复数据。

ETCD提供了两种主要的持久化方式：

1. **日志持久化（WAL）**： ETCD使用写入日志（Write-Ahead Log，WAL）来记录所有的写入操作。WAL是一个追加写入的顺序日志文件，它记录了所有的状态变更操作。每个写入操作都会追加到WAL中，并且在内存中进行相关的状态更新。然后，ETCD将WAL中的数据异步刷写到磁盘，以实现数据的持久化。
2. **快照持久化**： 为了减小WAL文件的大小和提高读取性能，ETCD还支持周期性地生成快照（Snapshot），将当前的数据状态以快照的形式保存到磁盘上。快照是一个压缩和紧凑的数据副本，在恢复时可以更快地加载和恢复数据。快照持久化是通过定期生成快照来确保数据持久化的。

结合日志持久化和快照持久化，ETCD的数据持久化过程如下：

1. 写入操作： 当ETCD集群接收到写入操作时，它首先会将写入操作追加到WAL中，并在内存中更新相关的状态。
2. WAL刷写： ETCD定期将WAL文件中的数据刷写到磁盘上。这是一个异步操作，可以提高写入性能，并减少对磁盘的频繁访问。
3. 快照生成： 定期或根据配置的触发条件，ETCD会生成一个快照，将当前的数据状态保存到磁盘上。快照是一个压缩和紧凑的数据副本，可以更快地加载和恢复数据。
4. 数据恢复： 当ETCD启动或重新启动时，它首先会加载最新的快照文件，然后读取之前的WAL文件并重新应用其中的操作，以恢复到最新的数据状态。通过这种方式，ETCD可以实现数据的持久化和可靠性。

需要注意的是，为了确保数据的完整性和一致性，ETCD还提供了从节点（follower）向主节点（leader）发送复制确认的机制，以防止数据丢失或损坏。从节点会将复制确认发送给主节点，并在确认接收后才认为数据已被持久化。

总结起来，ETCD通过使用日志持久化和快照持久化的方式，将数据持久化到磁盘上，以实现数据的安全性和可靠性。这种机制确保了即使在发生故障或重启的情况下，ETCD可以加载和恢复数据，并继续提供服务。

## 9、简述一下pod的重启策略

在 Kubernetes 中，可以通过设置 Pod 的重启策略来定义当 Pod 处于失败状态时的行为。Pod 的重启策略主要有以下三种：

1. Always（默认策略）：无论何时，只要 Pod 处于失败状态，Kubernetes 就会自动尝试重启该 Pod。这适用于大多数应用程序，确保在发生故障时快速恢复。
2. OnFailure：只有当 Pod 处于非零退出状态（例如应用程序崩溃或发生错误）时才会重启 Pod。如果 Pod 成功地终止，即使其退出代码为零，也不会触发重启操作。
3. Never：Pod 处于任何状态下都不会自动重启。这通常用于需要手动控制重启的特殊情况，例如调试或需要人工介入才能进行恢复的场景。

## 10、kubectl命令相关

1. kubectl get：用于获取资源对象的列表信息，如获取 Pod、Service、Deployment 等对象的状态和属性。
2. kubectl describe：用于获取资源对象的详细描述信息，如获取 Pod、Service、Node 等对象的详细配置和状态。
3. kubectl create：用于创建资源对象，如创建 Pod、Service、Namespace 等对象。
4. kubectl apply：用于将配置文件应用到集群中，可以用于创建、更新或删除资源对象。
5. kubectl delete：用于删除资源对象，如删除 Pod、Service、Deployment 等对象。
6. kubectl exec：用于在容器中执行命令，可以进入指定 Pod 中的容器，并执行特定的命令。
7. kubectl logs：用于查看 Pod 中容器的日志输出。
8. kubectl port-forward：用于将本地端口与 Pod 的端口进行转发，可以通过本地访问转发的端口来访问 Pod 的服务。
9. kubectl scale：用于调整 Deployment、ReplicaSet 或 StatefulSet 的副本数目。
10. kubectl expose：用于创建一个 Service，将一组 Pod 暴露为一个单一的访问点。
11. kubectl rollout：用于管理容器的滚动升级，可以进行发布新版本、回滚、暂停和恢复等操作。

## **11、有哪些类型的cgroup？**

1. **CPU**（cpu）：用于控制和限制 CPU 资源的分配，包括处理器时间片的分配、CPU 核心数量的限制等。
2. **内存**（memory）：用于控制和限制内存资源的分配，包括内存限额、SWAP 空间的使用限制等。
3. **设备**（devices）：用于控制和限制设备资源的访问，可以限制进程对特定设备的读写权限。
4. **网络**（net_cls、net_prio）：用于控制和限制网络资源的分配，包括对网络流量的分类和优先级设置。
5. **块设备**（blkio）：用于控制和限制块设备的 I/O 资源的分配，包括磁盘读写速度的限制、IOPS（每秒 I/O 操作数）的限制等。
6. **进程**（pids）：用于控制和限制进程数量的分配，可以限制一个 cgroup 中的进程数目。

## 12、pod的状态有哪些？

1. `Pending`：Pod 已经被创建，但还没有分配到任何节点上运行。
2. `Running`：Pod 正在运行，并且至少有一个容器在运行。
3. `Succeeded`：所有容器都成功地完成了任务并退出。
4. `Failed`：所有容器都已经完成运行，但至少有一个容器以非零状态退出。
5. `Unknown`：无法获取 Pod 的当前状态。

除了这些基本状态之外，还有一些其他的状态用于表示 Pod 的临时情况或错误状态：

- `ContainerCreating`：容器正在创建中。
- `Terminating`：Pod 正在被删除。
- `ContainerReady`：Pod 中的所有容器都已经准备就绪。

## 13、service如何实现负载均衡？

Kubernetes（简称为K8s）的Service提供了一种在集群内部实现负载均衡的机制。下面是Kubernetes中Service实现负载均衡的基本原理和方法：

1. 创建Service：首先，你需要创建一个Service对象来定义负载均衡的规则和配置。Service可以通过选择器（selector）来关联一组后端Pod。Service使用一组虚拟IP和端口来代表这组后端Pod，提供统一的访问入口。
2. 负载均衡算法：Kubernetes使用四种负载均衡算法来分配请求，分别是：
   - 轮询（Round Robin）：逐个按顺序将请求分配给后端Pod。
   - 最少连接（Least Connection）：将请求分配给当前连接数最少的后端Pod。
   - IP哈希（IP Hash）：根据客户端IP地址对后端Pod进行哈希计算，并将请求分配给对应的Pod。
   - 自定义（Custom）：允许用户自定义负载均衡算法。
3. IPVS实现负载均衡：Kubernetes使用Linux内核的IPVS（IP Virtual Server）实现负载均衡功能。IPVS是一种高性能、可扩展的负载均衡技术，能够在内核空间中进行快速的请求转发和负载均衡。
4. Service代理：Kubernetes会为每个Service创建一个虚拟IP，并在集群节点上启动一个Service代理（kube-proxy）。代理监听虚拟IP和端口，将请求转发到后端Pod。Service代理可以运行在两种模式下：
   - Userspace模式：使用iptables规则重定向流量到后端Pod。
   - IPVS模式：利用IPVS进行流量转发和负载均衡。

**总结起来，Kubernetes的Service通过创建虚拟IP和端口代表一组后端Pod，并借助IPVS实现负载均衡。Service代理监听虚拟IP和端口，将请求转发给后端Pod，根据负载均衡算法来选择目标Pod。这样，用户可以通过Service访问集群中的应用服务，而无需关心具体的后端Pod实例。**

## 14、**简述** **kube-proxy** **作用？**

答：kube-proxy 运行在所有节点上，它监听 apiserver 中 service 和 endpoint 的变化情况，创建路由规则以提供服务 IP 和负载均衡功能。简单理解此进程是 Service 的透明代理兼负载均衡器，其核心功能是将到某个 Service 的访问请求转发到后端的多个 Pod 实例上。

## **15、 简述** **kube-proxy** **iptables** **原理？**

答：Kubernetes 从 1.2 版本开始，将 iptables 作为 kube-proxy 的默认模式。iptables 模式下的 kube-proxy 不再起到 Proxy 的作用，其核心功能：通过 API Server 的Watch 接口实时跟踪 Service 与Endpoint 的变更信息，并更新对应的iptables 规则，Client 的请求流量则通过 iptables 的 NAT 机制“直接路由”到目标Pod。

## **16、 简述** **kube-proxy** **ipvs** **原理？**

答：IPVS 在 Kubernetes1.11 中升级为 GA 稳定版。IPVS 则专门用于高性能负载均衡， 并使用更高效的数据结构（Hash 表），允许几乎无限的规模扩张，因此被 kube-

proxy 采纳为最新模式。

在 IPVS 模式下，使用 iptables 的扩展 ipset，而不是直接调用 iptables 来生成规则链。iptables 规则链是一个线性的数据结构，ipset 则引入了带索引的数据结构，因此当规则很多时，也可以很高效地查找和匹配。

可以将 ipset 简单理解为一个 IP（段）的集合，这个集合的内容可以是 IP 地址、IP 网段、端口等，iptables 可以直接添加规则对这个“可变的集合”进行操作，这样做的好处在于可以大大减少 iptables 规则的数量，从而减少性能损耗。



## **17、简述 kube-proxy** **ipvs 和 iptables 的异同？**

答：iptables 与 IPVS 都是基于 Netfilter 实现的，但因为定位不同，二者有着本质的差别：iptables 是为防火墙而设计的；IPVS 则专门用于高性能负载均衡，并使用更高效的数据结构（Hash 表），允许几乎无限的规模扩张。

与 iptables 相比，IPVS 拥有以下明显优势：

l 1、为大型集群提供了更好的可扩展性和性能；

l 2、支持比 iptables 更复杂的复制均衡算法（最小负载、最少连接、加权等）；

l 3、支持服务器健康检查和连接重试等功能；

l 4、可以动态修改 ipset 的集合，即使 iptables 的规则正在使用这个集合。

## 18、Pod的调度策略有哪些？

1. 默认策略（Default）：这是 Kubernetes 中的默认调度策略。在默认情况下，Pod 可以被调度到任何可用的节点上，没有特定的限制条件。
2. 亲和性策略（Affinity）：亲和性策略允许你指定 Pod 与某些节点、节点标签或其他 Pod 之间的关系，以影响调度决策。可以使用亲和性策略来将 Pod 调度到特定的节点上，或者与其他 Pod 在同一节点上进行调度。
3. 反亲和性策略（Anti-Affinity）：反亲和性策略与亲和性策略类似，但是它允许你指定 Pod 与某些节点、节点标签或其他 Pod 之间的冲突关系。通过反亲和性策略，你可以阻止将多个相似的 Pod 调度到同一节点上，以提高容错性和可用性。
4. 资源限制（Resource Limits）：Pod 的调度策略还可以基于节点上的资源限制进行决策。你可以为 Pod 指定所需的 CPU 和内存资源，并配置最小和最大资源限制。通过资源限制，Kubernetes 可以基于节点上的资源使用情况来进行优先级排序和调度决策。
5. 亲和性和反亲和性的拓扑约束（Topology Constraint）：通过在 Pod 的调度策略中设置拓扑约束，你可以控制 Pod 在节点拓扑结构中的位置。这些拓扑约束可以是硬拓扑约束或软拓扑约束，用于确保 Pod 调度到特定的区域、机架或其他节点拓扑位置。

## 19、Kubernetes 中 Pod 的优雅退出机制？

pod 状态为 Terminating 的时候开始调用此钩子函数任务，一直到此任务完成或者达到 pod 的终止宽限期（默认为：30s，通过参数指定：terminationGracePeriodSeconds: 30），若此回调运行的时间超出了终止宽限期， kubelet 会发 SIGTERM 并再等 2 秒；如果没有配置 PreStop 的容器，kubelet 直接发送 SIGTERM，Pod 开始退出。


## **22. 简述** **Kubernetes** **中** **Pod** **的健康检查方式？**

答：对 Pod 的健康检查可以通过两类探针来检查：LivenessProbe 和ReadinessProbe。

l **LivenessProbe** **探针：**用于判断容器是否存活（running 状态），如果LivenessProbe 探针探测到容器不健康，则 kubelet 将杀掉该容器，并根据容器的重启策略做相应处理。若一个容器不包含 LivenessProbe 探针，kubelet 认为该容器的 LivenessProbe 探针返回值用于是“Success”。

l **ReadinessProbe** **探针：**用于判断容器是否启动完成（ready 状态）。如果ReadinessProbe 探针探测到失败，则 Pod 的状态将被修改。Endpoint Controller 将从 Service 的Endpoint 中删除包含该容器所在 Pod 的Endpoint。

l **startupProbe** **探针**：启动检查机制，应用一些启动缓慢的业务，避免业务长时间启动而被上面两类探针 kill 掉。

## 23.一个Pod内的容器共享哪些东西？

1. **网络命名空间**（Network Namespace）：同一个 Pod 内的容器共享相同的网络命名空间，它们可以相互通信，可以使用 localhost 或 Pod IP 地址进行通信。
2. **IPC 命名空间**（IPC Namespace）：同一个 Pod 内的容器共享 IPC 命名空间，它们可以使用 System V IPC 或 POSIX 共享内存来进行进程间通信。
3. **文件系统挂载**：多个容器可以共享相同的文件系统挂载，它们可以读取和写入相同的存储卷或共享目录。通过共享存储卷，容器之间可以方便地共享数据。
4. **环境变量**：Pod 级别的环境变量可以在同一个 Pod 内的所有容器中访问到。这意味着容器可以共享一些共同的配置或参数。
5. **PID 命名空间**（PID Namespace）：同一个 Pod 内的容器共享 PID 命名空间，它们可以查看和操作其他容器的进程。

## 24.创建deployment流程？

![26432-2orcxruqs6c.png](Tartarnus/image/通用面试题.images/fc1ba57a02538b94966c2bf2cad67ccc.png)

**创建pod流程：**

1. 客户端将创建 Pod 的请求发送给 Apiserver
2. Apiserver 将 Pod 信息写入 etcd,etcd 将写入结果响应给 Apiserver,Apiserver 将创建结果响应给客户端 (此时 Pod 处于 Pending 状态)
3. Scheduler 通过 Apiserver 的 watch 接口，获取到未调度的 Pod 的通知，根据调度算法选择一个 node 节点，告诉 Apiserver 这个 Pod 应该运行在哪个节点
4. Apiserver 将这个 Pod 和 node 的绑定信息更新到 etcd,etcd 将写入结果响应给 Apiserver
5. Kubelet 通过 Apiserver 的 watch 接口，获取到当前节点有创建 Pod 的通知，Kubelet 调用 docker 创建容器，Kubelet 将 Pod 运行状态发送给 Apiserver
6. Apiserver 将 Pod 状态信息更新到 etcd



**创建 Deployment 流程：**

1. 客户端将创建 Deployment 的请求发送给 Apiserver
2. Apiserver 将 Deployment 信息写入 etcd,etcd 将写入结果响应给 Apiserver,Apiserver 将创建结果响应给客户端 (此时未经过 ControllerManager,deployment 的 READY 状态为 0)
3. ControllerManager 通过 Apiserver 的 watch 接口，获取到新增的 Deployment 资源，Deployment controller 向 Apiserver 发送创建 RS 的请求，Apiserver 将 RS 信息写入 etcd。。。
4. ControllerManager 通过 Apiserver 的 watch 接口，获取到新增的 ReplicaSet 资源，ReplicaSet controller 向 Apiserver 发送创建 Pod 的请求，Apiserver 将 Pod 信息写入 etcd。。。
5. Scheduler 通过 Apiserver 的 watch 接口，获取到未调度的 Pod 的通知，根据调度算法选择一个 node 节点，告诉 Apiserver 这个 Pod 应该运行在哪个节点
6. Apiserver 将这个 Pod 和 node 的绑定信息更新到 etcd,etcd 将写入结果响应给 Apiserver
7. Kubelet 通过 Apiserver 的 watch 接口，获取到当前节点有创建 Pod 的通知，Kubelet 调用 docker 创建容器，Kubelet 将 Pod 运行状态发送给 Apiserver
8. Apiserver 将 Pod 状态信息更新到 etcd

## 30.有几种方式使用configmap？

1. 在容器命令和参数内
2. 容器的环境变量
3. 在只读卷里面添加一个文件，让应用来读取
4. 编写代码在 Pod 中运行，使用 Kubernetes API 来读取 ConfigMap

## **35. 简述** **Kubernetes** **镜像的下载策略？**

答：K8s 的镜像下载策略有三种：Always、Never、IFNotPresent。

l **Always**：镜像标签为 latest 时，总是从指定的仓库中获取镜像。

l **Never**：禁止从仓库中下载镜像，也就是说只能使用本地镜像。

l **IfNotPresent**：仅当本地没有对应镜像时，才从目标仓库中下载。默认的镜像下载策略是：当镜像标签是latest 时，默认策略是 Always；当镜像标签是自定义时

（也就是标签不是 latest），那么默认策略是 IfNotPresent。

## **39. 简述** **Kubernetes** **Scheduler** **使用哪两种算法将** **Pod** **绑定到** **worker** **节点？**

答：Kubernetes Scheduler 根据如下两种调度算法将 Pod 绑定到最合适的工作节点：

l **过滤（Predicates）**：输入是所有节点，输出是满足预选条件的节点。kube- scheduler 根据预选策略过滤掉不满足策略的 Nodes。如果某节点的资源不足或者不满足预选策略的条件则无法通过预选。如“Node 的label 必须与 Pod 的Selector 一致”。

l **打分（Priorities）**：输入是预选阶段筛选出的节点，优选会根据优先策略为通过预选的 Nodes 进行打分排名，选择得分最高的 Node。例如，资源越富裕、负载越小的 Node 可能具有越高的排名。

## **40. 简述** **Kubernetes** **kubelet** **的作用？**

答：在 Kubernetes 集群中，在每个 Node（又称 Worker）上都会启动一个 kubelet

服务进程。该进程用于处理 Master 下发到本节点的任务，管理 Pod 及 Pod 中的容器。

每个 kubelet 进程都会在 API Server 上**注册节点自身的信息**，定期向 Master **汇报节点资源的使用情况**，并通过 cAdvisor 监控容器和节点资源。



## 41、Service如何关联pod？

在 Kubernetes 中，Service 通过**标签选择器**（Label Selector）来关联 Pod。

## 42、clusterIp类型如何找寻pod？

通过endpoints列表

## 43、etcd满足CAP理论的哪几个？

**CP**，当发生网络分区或节点故障时，etcd 使用 Raft 算法从可用的节点中选举新的领导者，并继续处理客户端的请求。然而，在选举新的领导者的过程中，etcd 的可用性会受到影响，因为在选举期间，系统可能无法正常地处理客户端请求。

## 44、k8s有哪些组件？（k8s组件）

一、Master 组件

1. API Server：Kubernetes 的主要管理组件。所有的管理任务都是通过 API Server 进行的。它是 Kubernetes 的前端，处理和响应命令行接口（CLI）、用户接口（UI）或其他管理系统的请求。

2. etcd：这是 Kubernetes 的主要键值存储系统。所有集群数据都储存在 etcd 中，包括节点、pods、配置等。

3. Scheduler：此组件负责在各个节点上分配 pods。它根据各个节点的资源利用率、输入的资源需求、数据位置、策略等因素做出决策。

4. Controller Manager：这是一种后台线程，它处理集群中的常规任务。主要的 Controller 包括 Node Controller、Replication Controller、Endpoints Controller 和 Service Account & Token Controllers。

二、Node 组件

1. Kubelet：这是运行在每个节点上的主要节点代理。它确保 pod（包含在其中的容器）运行正常。
2. Kube-proxy：Kube-proxy 是 Kubernetes 服务的网络代理，运行在每个节点上，维护网络规则和进行连接转发。
3. Container Runtime：这是用于运行容器的软件。Kubernetes 支持多种容器运行时，包括 Docker、containerd、CRI-O 和其他实现 Kubernetes Container Runtime Interface (CRI) 的运行时。

## 45、什么是StatefulSet？

StatefulSet 是 Kubernetes 提供的一种控制器（Controller）类型，用于管理有状态应用程序的部署和管理。有状态应用程序是那些在运行过程中需要维护持久状态或标识性信息的应用程序，通常涉及数据库、缓存或分布式系统等。

与普通的 Deployment 不同，StatefulSet 提供了一种**有序、唯一且可预测**的标识，每个 Pod 都有一个唯一的序号。这使得 StatefulSet 能够在部署和扩展有状态应用程序时保持稳定的网络标识和存储标识。每个 Pod 运行的实例都具有唯一的 DNS 名称，方便进行服务发现和网络通信。

StatefulSet 还与持久化存储密切相关。它可以与 PersistentVolumeClaim（PVC）结合使用，以提供每个 Pod 的持久化存储。当创建新的 Pod 实例时，它会绑定到一个相应的持久化存储卷，并将其挂载到容器中，从而保证了持久化数据的可靠性和稳定性。

通过使用 StatefulSet，Kubernetes 用户可以轻松地管理和扩展有状态应用程序，同时充分利用 Kubernetes 的弹性和高可用特性。无论是运行数据库集群、分布式缓存还是其他有状态应用程序，StatefulSet 提供了一种声明式的方式来定义和管理它们。

## 46、k8s的污点与容忍度？

在Kubernetes中，“污点”（Taint）是一种属性，是用来标记一个节点不可调度的标记。每个节点可以有零个或多个污点。当一个节点拥有某个污点时，只有具有相应容忍度的Pod才能在该节点上被调度。

## 47、runc创建一个容器的流程是怎么样的？

runc创建容器的大致流程如下：

1. 准备rootfs文件系统：rootfs是包含容器文件系统的最小环境。在创建容器前，需要准备好rootfs文件系统，并将其保存到适当的位置。
2. 设置容器配置：设置容器的配置项，包括容器的名称、ID、rootfs路径、资源限制等。
3. 创建容器的命名空间：通过调用Linux的clone()系统调用，创建容器的命名空间，包括PID、网络、挂载点等命名空间。
4. 配置容器资源限制：通过控制组（cgroup）机制限制容器可以使用的系统资源（如CPU、内存、I/O等资源）。
5. 配置容器文件系统：在容器的命名空间中挂载rootfs文件系统，并配置proc、sys等文件系统的挂载点。这样容器就可以看到自己的文件系统，并且能够访问主机上的其他文件系统。
6. 启动容器进程：通过调用Linux的execve()系统调用，在容器中启动要运行的进程。
7. 清理容器：在容器进程退出后，需要清理容器的所有资源，包括释放容器的命名空间、卸载文件系统等。

## 48、namespace是怎么实现隔离的？

在Linux系统中，Namespace是一种轻量级的虚拟化机制，可以将系统的各种资源进行隔离，使得不同进程之间看到的资源和环境是不同的。

下面是Linux Namespace实现隔离的主要原理：

1. 创建Namespace：Linux内核提供了创建和管理Namespace的系统调用，通过使用这些系统调用，可以在Linux系统中创建新的Namespace。例如，可以通过clone()系统调用创建新的进程并指定需要隔离的Namespace，也可以使用unshare()函数将当前进程移动到新的Namespace中。
2. 隔离资源：Linux Namespace可以隔离多种资源，包括进程、网络、文件系统、用户、IPC等。当新的Namespace创建成功后，相关的资源会被隔离到新的命名空间中，并且不同的Namespace之间看到的资源是不同的。
3. 命名空间标识符：在Linux内核中，**每个Namespace都有一个唯一的标识符，称为Namespace ID。Namespace ID是在创建Namespace时由内核自动生成的，并且在整个系统中都是唯一的。通过Namespace ID，内核可以区分不同的Namespace，并确保它们之间的隔离性**。
4. 资源限制：在Linux Namespace中，可以通过设置一些限制来对隔离的资源进行控制。例如，可以使用cgroup来限制进程的CPU和内存使用。此外，还可以使用Namespace来限制进程对文件系统的访问权限，或者将进程隔离到一个特定的网络命名空间中。

总之，Linux Namespace通过隔离不同的资源和环境，使得不同进程之间看到的资源和环境是不同的，从而实现了轻量级的虚拟化。在实现这个过程中，内核提供了一些系统调用和数据结构，通过这些接口可以创建Namespace、隔离资源、管理Namespace等。

![img](Tartarnus/image/通用面试题.images/v2-2d8c38d71c5c86b4a19625e5accfe0d0_720w.webp)

## 49、client-go组件？

client-go 组件：

Reflector: 定义在 /tools/cache 包内的 Reflector 类型 中的 reflector 监视 Kubernetes API 以获取指定的资源类型 (Kind)。完成此操作的函数是 ListAndWatch。监视可以用于内建资源，也可以用于自定义资源。当 reflector 通过监视 API 的收到关于新资源实例存在的通知时，它使用相应的 listing API 获取新创建的对象，并将其放入 watchHandler 函数内的 Delta Fifo 队列中。

Informer: 在 /tools/cache 包内的基础 controller 中定义的一个 informer 从 Delta FIFO 队列中弹出对象。完成此操作的函数是 processLoop。这个基础 controller 的任务是保存对象以供以后检索，并调用 controller 将对象传递给它。

Indexer: indexer 为对象提供索引功能。它定义在 /tools/cache 包内的 Indexer 类型。一个典型的索引用例是基于对象标签创建索引。Indexer 可以基于多个索引函数维护索引。Indexer 使用线程安全的数据存储来存储对象及其键值。在 /tools/cache 包内的 Store 类型 定义了一个名为 MetaNamespaceKeyFunc 的默认函数，该函数为该对象生成一个名为 <namespace>/<name> 组合的对象键值。

Custom Controller 组件：

Informer reference: 这是一个知道如何使用自定义资源对象的 Informer 实例的引用。您的自定义控制器代码需要创建适当的 Informer。

Indexer reference: 这是一个知道如何使用自定义资源对象的 Indexer 实例的引用。您的自定义控制器代码需要创建这个。您将使用此引用检索对象，以便稍后处理。

Resource Event Handlers: 当 Informer 想要分发一个对象给你的控制器时，会调用这些回调函数。编写这些函数的典型模式是获取已分配对象的键值，并将该键值放入一个工作队列中进行进一步处理。

Work queue: 这是在控制器代码中创建的队列，用于将对象的分发与处理解耦。编写 Resource Event Handler 函数来提取所分发对象的键值并将其添加到工作队列中。

Process Item: 这是在代码中创建的处理 work queue 中的 items 的函数。可以有一个或多个其他函数来执行实际的处理。这些函数通常使用 Indexer 引用 或 Listing wrapper 来获取与键值对应的对象。

![img](Tartarnus/image/通用面试题.images/v2-b7ba279dad75649b02f3cfe6d81d8fcf_720w.webp)

## 50、client-go的lister和watch有什么区别？

在使用 Kubernetes 客户端库 client-go 时，Lister 和 Watcher 是两种不同的资源访问方式。

1. Lister（列表器）： Lister 提供了对指定 Kubernetes 资源的全量列表操作。它会从 API Server 获取整个资源列表并将其缓存在本地内存中，允许应用程序快速地对资源进行遍历和查询。Lister 其实是一个本地缓存的数据结构，能够提供高效的资源查找。在初始化时，Lister 会通过 API Server 请求所有资源，并将其存储在内存中。之后，当需要获取特定资源时，Lister 可以直接从内存中返回结果，而无需再与 API Server 进行通信。但需要注意的是，Lister 仅提供静态的资源列表，不会自动更新，因此不适用于需要实时数据的场景。
2. Watcher（监听器）： Watcher 则是通过监听 Kubernetes 资源的变化来获取实时事件的机制。Watcher 会建立与 API Server 的长连接，实时接收资源的变更事件（如创建、更新、删除等）。当有事件发生时，Watcher 将事件通知给客户端，使得应用程序能够立即作出响应。Watcher 将持续监听事件的发生，直到主动停止监听。

总结来说，Lister 适合用于静态全量数据的查询，而 Watcher 适合用于实时事件的监听。对于需要频繁查询资源列表的场景，Lister 的缓存机制可以提高性能和效率；而对于需要及时感知资源变化并作出响应的场景，Watcher 提供了实时事件的订阅和处理能力。根据具体的需求，可以选择适合的方式来操作 Kubernetes 资源。

## 51、k8s为什么要禁用swap？

**1、什么是swap？**

Swap（交换空间）是一种在操作系统中用于扩展物理内存的技术。在计算机的内存管理中，当物理内存不足时，操作系统可以将一部分暂时不活跃的内存页面（页）写入到硬盘上的交换空间中，并从交换空间中读取其他需要的页面到内存中。

Swap 的作用是在物理内存不足时提供额外的虚拟内存，使得系统能够继续执行运行。当内存紧张时，操作系统会将一些较少使用或者暂时不需要的数据从内存中置换出来，腾出空间给其他数据使用。

当系统需要访问被置换到交换空间的页面时，操作系统会将这些页面从硬盘读取回内存，并将其他无用的页面置换到交换空间中。这个过程是透明的，对应用程序来说是无感知的。

交换空间通常设置在磁盘的特定分区或者文件中。在 Linux 系统中，可以通过设备文件（如 /dev/sda2）或者专用的交换文件（如 /swapfile）来指定交换空间。

需要注意的是，虽然 Swap 提供了额外的虚拟内存，但与物理内存相比，交换空间的读写速度要慢很多，因为它涉及到磁盘操作。因此，在性能要求高的系统中，过多地依赖 Swap 可能导致系统性能下降。

在一些情况下，如在使用 Kubernetes 等容器管理平台时，禁用 Swap 是为了避免性能和可靠性问题。

**禁用原因：**

在 Kubernetes 中禁用 Swap（虚拟内存）是出于性能和可靠性方面的考虑，主要有以下几个原因：

1. 内存管理： 假设 Kubernetes 中的一个 Pod 允许使用 1GB 内存，但是由于操作系统会将少许的内存交换到硬盘上，如果开启了 Swap，那么运行该 Pod 的节点可能会交换一部分内存到硬盘上，这样就会导致节点的 I/O 操作大量增加，影响其他 Pod 的性能，并且还可能会导致 OOM（Out Of Memory）问题。
2. 安全性： 开启 Swap 后，内核需要将机密信息（如密码、密钥等）交换到磁盘上，这样会增加攻击者窃取敏感信息的风险。
3. Kubelet 配置： Kubernetes 默认配置文件中禁用了 Swap，如果在节点上启用了 Swap，那么可能会导致 Kubelet 在启动时出现问题。

因此，在 Kubernetes 中强烈建议禁用 Swap。可以通过编辑节点的 /etc/fstab 文件，注释掉 Swap 分区的相关条目，然后重新加载文件系统即可禁用 Swap。

需要注意的是，为了避免出现 OOM 问题，应该合理设置容器的内存限制（如 resource limits 和 requests）以确保容器有足够的内存可用。


# Linux面试题

## 命令集

### 磁盘管理

**df**：命令用于显示目前在 Linux 系统上的文件系统磁盘使用情况统计。

- 文件-a, --all 包含所有的具有 0 Blocks 的文件系统
- 文件--block-size={SIZE} 使用 {SIZE} 大小的 Blocks
- **文件-h, --human-readable 使用人类可读的格式(**预设值是不加这个选项的...)
- 文件-H, --si 很像 -h, 但是用 1000 为单位而不是用 1024
- 文件-i, --inodes 列出 inode 资讯，不列出已使用 block
- 文件-k, --kilobytes 就像是 --block-size=1024
- 文件-l, --local 限制列出的文件结构
- 文件-m, --megabytes 就像 --block-size=1048576
- 文件--no-sync 取得资讯前不 sync (预设值)
- 文件-P, --portability 使用 POSIX 输出格式
- 文件--sync 在取得资讯前 sync
- 文件-t, --type=TYPE 限制列出文件系统的 TYPE
- 文件-T, --print-type 显示文件系统的形式
- 文件-x, --exclude-type=TYPE 限制列出文件系统不要显示 TYPE
- 文件-v (忽略)
- 文件--help 显示这个帮手并且离开
- 文件--version 输出版本资讯并且离开

**du**：显示指定的目录或文件所占用的磁盘空间。

- -a或-all 显示目录中个别文件的大小。
- -b或-bytes 显示目录或文件大小时，以byte为单位。
- -c或--total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。
- -D或--dereference-args 显示指定符号连接的源文件大小。
- **-h或--human-readable 以K，M，G为单位，提高信息的可读性。**
- -H或--si 与-h参数相同，但是K，M，G是以1000为换算单位。
- -k或--kilobytes 以1024 bytes为单位。
- -l或--count-links 重复计算硬件连接的文件。
- -L<符号连接>或--dereference<符号连接> 显示选项中所指定符号连接的源文件大小。
- -m或--megabytes 以1MB为单位。
- **-s或--summarize 仅显示总计。**
- -S或--separate-dirs 显示个别目录的大小时，并不含其子目录的大小。
- -x或--one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。
- -X<文件>或--exclude-from=<文件> 在<文件>指定目录或文件。
- --exclude=<目录或文件> 略过指定的目录或文件。
- **-d或--max-depth=<目录层数> 超过指定层数的目录后，予以忽略。（常用）**
- --help 显示帮助。
- --version 显示版本信息。



## 1、操作系统内核态和用户态的区别

内核态是操作系统的特权模式，具有最高的权限。在内核态下，CPU 可以执行任意的机器指令，并访问所有的计算机资源，如内存、设备等。内核态主要用于执行操作系统核心代码，控制硬件资源、管理进程和文件系统等底层操作。

用户态是应用程序的一种运行模式，具有较低的权限。在用户态下，CPU 受限制只能执行受限的指令，并且只能访问用户空间的资源。用户态不允许直接访问核心资源，必须通过系统调用接口向操作系统发起请求，由操作系统在内核态下执行相应的请求操作。

区别：

1. 权限级别：内核态具有最高权限，可以执行所有机器指令并访问所有计算机资源；用户态权限较低，受限于操作系统的保护机制，无法直接访问核心资源。
2. 资源访问：内核态可以直接访问系统的核心资源，如物理内存、硬盘、网络设备等；用户态只能通过系统调用接口向操作系统请求访问核心资源。
3. 运行环境：内核态运行操作系统的核心代码，控制和管理计算机硬件资源；用户态运行应用程序，通过系统调用接口向操作系统请求服务。
4. 安全性：内核态的代码需要经过严格的测试和验证，以确保操作系统的正确性和安全性；用户态的应用程序受限于操作系统的保护机制，可以提高系统的稳定性和安全性。

## 2、Linux 中进程有哪几种状态？在 ps 显示出来的信息中，分别用什么符号表示的？

（1）不可中断状态：进程处于睡眠状态，但是此刻进程是不可中断的。不可中断， 指进程不响应异步信号。

（2）暂停状态/跟踪状态：向进程发送一个 SIGSTOP 信号，它就会因响应该信号 而进入 TASK_STOPPED 状态;当进程正在被跟踪时，它处于 TASK_TRACED 这个特殊的状态。

“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。

（3）就绪状态：在 run_queue 队列里的状态

（4）运行状态：在 run_queue 队列里的状态

（5）可中断睡眠状态：处于这个状态的进程因为等待某某事件的发生（比如等待 socket 连接、等待信号量），而被挂起

（6）zombie 状态（僵尸）：父亲没有通过 wait 系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉

（7）退出状态

```
D 不可中断 Uninterruptible（usually IO）
R 正在运行，或在队列中的进程
S 处于休眠状态
T 停止或被追踪
Z 僵尸进程
W 进入内存交换（从内核 2.6 开始无效）
X 死掉的进程
```

## 3、什么是用户态？什么是内核态？

用户态（User Mode）和内核态（Kernel Mode）是操作系统中的两种不同的执行状态。

1. 用户态（User Mode）：
   - 用户态是指进程运行在**受限的、受控制**的环境中，并且只能访问有限的资源和执行受限的操作。
   - 在用户态下运行的进程无法直接访问计算机硬件资源或其他敏感资源，例如磁盘、网络设备等。
   - 用户态下运行的进程执行的指令通常是非特权指令，即不能执行特权操作的指令。
   - 当应用程序运行时，它处于用户态。大多数应用程序在用户态运行。
   - cpu权限是**ring3**级别
2. 内核态（Kernel Mode）：
   - 内核态是操作系统内核运行的**特权模式**，拥有完全的系统资源和控制权限。
   - 内核态下运行的进程可以访问和操作计算机的所有资源，包括硬件设备和敏感资源。
   - 内核态下运行的进程拥有执行特权操作的权限，可以执行特权指令，如修改内存页表、更改中断向量表等。
   - 操作系统内核在内核态中运行，负责管理和控制计算机的各种资源和提供服务。
   - cpu权限是在**ring0**级别

## 4、进程间的通信方式有哪些？

进程间通信（Inter-Process Communication, IPC）是指操作系统中不同进程之间进行数据交换和通信的机制。常见的进程间通信方式包括以下几种：

1. **管道**（Pipe）：管道是一种半双工的通信方式，可以在具有亲缘关系的进程之间进行通信。管道分为**匿名管道**和**命名管道**两种形式。

2. **信号量**（Semaphore）：信号量是一种用于进程同步和互斥的机制，可以通过对信号量进行 PV 操作（Wait 和 Signal）来实现进程间的通信和资源的控制。

3. **共享内存**（Shared Memory）：共享内存是一种高效的通信方式，多个进程可以同时访问同一块共享内存区域，从而实现数据的共享和传递。

4. **消息队列**（Message Queue）：消息队列是一种基于消息传递的通信方式，可以通过在消息队列中发送、接收和处理消息来实现进程间的通信。

5. **套接字**（Socket）：套接字是一种网络编程中常用的进程间通信方式，可以在同一台计算机上或跨网络进行进程间通信。

   

这些进程间通信方式各有特点，具体选择哪种方式取决于应用程序的需求和设计。在实际应用中，通常会结合多种进程间通信方式来满足不同的需求。

## 5、内核态切换到用户态做了哪些事情？

1. **保存内核态的上下文信息**：在内核态执行期间，CPU的各种寄存器、标志位、堆栈指针等状态会发生变化。因此，在切换到用户态之前，操作系统需要将这些关键的内核态信息保存下来，以便于日后恢复。
2. **加载用户态的状态**：操作系统通过内核栈切换到用户进程的栈，并修改CPU的内部寄存器，将其置为用户态执行所需的状态。这个过程可能会涉及到地址空间切换、页表切换、权限级别切换等操作。
3. **将 CPU 控制权转移给用户进程**：在完成上述操作后，操作系统将 CPU 控制权交给用户进程，使其开始执行用户态代码。

## 6、进程的调度方式有几种？

### 1.先来先服务调度算法（FCFS：firstcome first service）

先来先服务(FCFS)调度算法即可适用于作业调度，也可以适用于进程调度。当此算法在作业调度中时，它每次选取一个或多个最先进入该队列的作业，将它们调入内存，分配资源，创建进程，然后放入就绪队列。在进程调度中，就是每次选取就绪队列中最先进入该队列的进程，为之分配处理机，使它投入运行。只有该进程运行到结束或者被阻塞无法运行后才放弃处理机，调度算法选取下一个进程。FCFS算法简单易行，是一种非抢占式策略，但性能却不大好，因为在调用短进程并且对I/O资源调用平凡的进程时，按顺序进行会浪费处理机的资源。

### 2.短进程优先算法（SJF：Shortest Job First或SPN：ShortestProcess Next)

对预计“CPU执行期”最短的进程优先分配处理机，通常后来的短进程不抢先正在执行的进程。
**该算法的优点在于**：相比FCFS算法改善了CPU的平均周转时间，和进程的平均等待时间，提高系统的吞吐量。
**该算法的缺点在于**：长作业可能长时间都得不到处理机的使用权；未能依据进程的紧迫程度来划分进程的优先级；难以准确估计进程的执行时间。

### 3.时间片轮转算法（RR：Round Robin）

该算法的特性是让所有进程等待的时间和享受服务的时间都公平公正。具体过程是：

- 按FCFS的排列方式将所有需要处理机资源的进程排序
- 规定一个时间片长度，可以是几个ms到几百个ms
- 选取队列中队首的进程，让它执行一个时间片长度的时间
- 执行完毕之后将此程序放到队列的队尾，再次取新的队首进行上述操作
- 注意：在执行时间片的过程中，进程可以随时因为某种原因（阻塞）退出

### 4.多级反馈队列算法(Round Robin with Multiple Feedback)

此算法可分为三步进行讲解：

- 先创建N个队列，用来存储进程信息。每个队列都有自己的优先级，第一个队列优先级最高，下来是第二个队列，以此类推，第N个队列优先级最低。
- 优先级不同的队列中的进程，运行的时间片长度也不同，第一个队列最短比如是i，第二个队列的时间片长度就是2i，以此类推。当一个进程需要执行时，先放到第一个队列的末尾，然后从第一个队列的队首开始提取进程分配处理机资源。提取到此进程时，运行本层时间片长度的时间，如果该进程没有运行完就把该进程放到第二个优先级队列的末尾等待被提取。
- 只有当优先级高的队列空闲了，才会去下一个队列的队首提取进程。
- 如果处理机正在运行后面第i个队列的进程，前面第一个队列插入了一个进程，这时会直接放弃正在运行的进程，将它插入到第i个队列的末尾，去运行新插入的优先级高的进程。

### 5.优先级算法（Priority Scheduling）

为了照顾紧迫进程，使之在进入系统后便获得优先处理，引入了优先级算法。可进一步把该算法分成如下两种：

- 非抢占式优先权算法 ：这种方式下，系统一旦把处理机分配给某进程后，一直要等到该进程运行完毕，或者阻塞。才能将处理机分配给下一个进程。
- 抢占式优先权调度算法 ：这种方式下，只要有进程比正在运行中进程的优先级高，就可以直接打断运行中的进程，系统给优先级高的进程分配处理机。

### 6.最高响应比优先法(HRN，Highest Response_ratio Next)

该算法是对FCFS方式和SJF方式的一种综合平衡。FCFS方式只考虑每个作业的等待时间而未考虑执行时间的长短，而SJF方式只考虑执行时间而未考虑等待时间的长短。因此，这两种调度算法在某些极端情况下会带来某些不便。HRN调度策略同时考虑每个作业的等待时间长短和估计需要的执行时间长短，从中选出响应比最高的作业投入执行。响应比R定义如下：
**R =(W+T)/T = 1+W/T**
其中T为该作业估计需要的执行时间，W为作业在后备状态队列中的等待时间。每当要进行作业调度时，系统计算每个作业的响应比，选择其中R最大者投入执行。这样，即使是长作业，随着它等待时间的增加，W / T也就随着增加，也就有机会获得调度执行。这种算法是介于FCFS和SJF之间的一种折中算法。由于长作业也有机会投入运行，在同一时间内处理的作业数显然要少于SJF法，从而采用HRN方式时其吞吐量将小于采用SJF法时的吞吐量。另外，由于每次调度前要计算响应比，系统开销也要相应增加。



## 7、linux有几种namespace？

在Linux操作系统中，有八种类型的命名空间（Namespace），它们提供了对不同资源的隔离和共享，以实现更高效的资源利用和更好的安全性。这些命名空间是：

1. Mount Namespace（挂载命名空间）：每个进程在挂载命名空间内都有自己的一份文件系统视图，它们可以拥有不同的根目录和挂载点，且对于文件系统操作具有独立性。
2. UTS Namespace（UTS命名空间）：UTS代表Unix Timesharing System，它提供了每个进程独立的主机名和域名。在不同的UTS命名空间中，进程可以有不同的主机名和域名标识。
3. PID Namespace（进程命名空间）：每个PID命名空间内都有一个独立的进程ID空间，即相同PID在不同的PID命名空间中可以表示不同的进程。这使得每个PID命名空间中的进程可以独立地看到和管理自己的进程树。
4. Network Namespace（网络命名空间）：每个网络命名空间内都有一个独立的网络栈，包括网络设备、IP地址、路由表和防火墙规则等。通过网络命名空间，可以实现不同网络环境之间的隔离。
5. IPC Namespace（进程间通信命名空间）：IPC命名空间提供了独立的进程间通信机制，包括System V IPC和POSIX消息队列、信号量和共享内存等。每个IPC命名空间内的进程只能与同一命名空间内的其他进程进行通信。
6. User Namespace（用户命名空间）：用户命名空间为每个命名空间提供了独立的用户和用户组标识。这意味着在不同的用户命名空间中，相同的用户ID和组ID可以表示不同的用户和用户组。
6. Time Namespace（时间命名空间）： Time Namespace用于隔离进程的系统时间相关信息。在Time Namespace中，每个命名空间内的进程拥有自己独立的时间概念，包括系统时间、定时器、时间戳等。不同的Time Namespace中的进程可以拥有不同的时间设置，互相之间互不干扰。这种隔离机制对于容器化环境和需要进行时间调整的场景非常有用，例如在测试环境中模拟不同时间点的行为。
6. Cgroup Namespace（控制组命名空间）： Cgroup Namespace用于隔离进程的资源控制。Cgroup（控制组）是Linux内核提供的一种机制，用于对进程和进程组的资源使用进行限制和管理。Cgroup Namespace允许在不同的命名空间中独立创建和管理控制组，让每个命名空间内的进程只能看到自己所属命名空间中的资源控制限制。这样可以实现对不同组的进程进行资源隔离和限制，确保各个组之间的资源使用不会相互干扰。

这些命名空间可以独立地应用于进程，使得不同的进程可以在不同的命名空间中运行，从而实现资源的隔离和不同层级的控制。这种命名空间机制在容器化技术中得到广泛应用，如Docker和Kubernetes等。

# 通用面试题

## 1、什么是对称加密？什么是非对称加密？

对称加密：

对称加密是指使用同一个密钥进行加密和解密的加密算法。发送方使用密钥对数据进行加密，然后将加密后的数据发送给接收方，接收方再使用同样的密钥对数据进行解密。常见的对称加密算法包括**DES**、**AES**和**RC4**等。对称加密算法具有加密速度快、效率高的特点，适合用于大量数据的加密和解密。然而，对称加密存在一个密钥分发问题，即如何安全地将密钥传输给接收方。

非对称加密：

非对称加密也被称为公钥加密，它使用一对相关联的密钥：公钥和私钥。发送方使用接收方的公钥对数据进行加密，只有持有相应私钥的接收方才能解密该数据。相比于对称加密，非对称加密更为安全，因为公钥可以自由发布而不会泄露私钥。一些常见的非对称加密算法包括**RSA**和Elliptic Curve Cryptography (**ECC**)。然而，非对称加密算法相对而言较为复杂，加密和解密的速度较慢，不适合加密大量数据。

## 2、ca证书的编码格式有哪些？

1. **PEM**（Privacy-Enhanced Mail）：PEM 是一种常见的证书编码格式，使用 Base64 编码表示证书的 ASCII 字符串。通常以 `.pem` 扩展名结尾，可以包含公钥证书、私钥和证书链等。
2. **DER**（Distinguished Encoding Rules）：DER 是一种二进制编码格式，通常以 `.der` 或 `.cer` 扩展名结尾。DER 格式的证书经过了 ASN.1（Abstract Syntax Notation One，抽象语法标记一）编码。
3. **PKCS**#7 / P7B：PKCS#7 或 P7B 是一种用于证书存储的格式，通常以 `.p7b` 或 `.p7c` 扩展名结尾。它可以包含一个或多个证书及其证书链。
4. **PKCS**#12 / PFX：PKCS#12 或 PFX 是一种用于证书和私钥存储的格式，通常以 `.pfx` 或 `.p12` 扩展名结尾。它可以包含证书、私钥和证书链，并可以通过密码进行保护。

## 3、有几种io模型？

1. **阻塞式 I/O：**
   - 在阻塞式 I/O 中，应用程序发起 I/O 操作后会被阻塞，直到操作完成才能继续执行后续代码。
   - 当进行阻塞式读取时，如果数据还未准备好，应用程序会一直等待，直到数据可用。类似地，阻塞式写入也可能导致应用程序阻塞直至写入完成。
2. **非阻塞式 I/O：**
   - 在非阻塞式 I/O 中，应用程序发起 I/O 操作后可以立即返回并继续执行后续代码，不必等待操作的完成。
   - 当进行非阻塞式读取时，如果数据尚未准备好，操作可能会返回一个错误码，提示数据不可用。类似地，非阻塞式写入可能会返回一个错误码，表示写入无法立即完成。
3. **I/O 多路复用（I/O Multiplexing）：**
   - I/O 多路复用模型通过使用 select、poll 或 epoll 等机制，允许应用程序同时监听多个 I/O 事件。
   - 当有任何一个 I/O 事件就绪时，应用程序被通知可以对该事件进行操作，而不是像阻塞式 I/O 一样被阻塞等待。
   - I/O 多路复用适用于需要同时管理多个 I/O 通道，以提高并发性能的场景。
4. **信号驱动式 I/O（Signal-driven I/O）：**
   - 信号驱动式 I/O 模型中，应用程序通过指定信号处理函数，在数据准备就绪时接收到一个信号。
   - 当数据准备好时，操作系统向应用程序发送一个信号，应用程序会调用事先注册的信号处理函数来处理数据。
5. **异步 I/O（Asynchronous I/O）：**
   - 在异步 I/O 模型中，应用程序发起 I/O 操作后可以立即返回，并继续执行其他任务。
   - 当 I/O 操作完成时，操作系统会通知应用程序，应用程序可以处理已完成的 I/O 请求。
   - 异步 I/O 通常使用回调函数或事件通知机制来处理 I/O 完成的事件。

## 4、什么是cap理论

CAP 理论，也称为 Brewer's 定理，指的是在分布式计算系统中，**一致性（Consistency）**、**可用性（Availability）**和**分区容错性（Partition tolerance）**这三个特性无法同时满足的原则。

## 5、分布式事务如何保证强一致性？

在分布式系统中，保证强一致性的分布式事务通常使用两阶段提交（Two-Phase Commit，简称2PC）协议来实现。以下是2PC协议的基本流程：

1. 准备阶段（Prepare Phase）：
   - 协调者（Coordinator）向所有参与者（Participants）发送事务准备请求，并等待参与者的响应。
   - 参与者执行事务操作，并将 Undo 和 Redo 日志记录到事务日志中。
   - 参与者向协调者发送准备就绪或者失败的响应。
2. 提交阶段（Commit Phase）：
   - 如果所有参与者都准备就绪，协调者向参与者发送事务提交请求。
   - 参与者收到提交请求后，执行事务的最终提交操作并释放相关资源。
   - 参与者向协调者发送提交完成的响应。

如果任意一个参与者在准备阶段返回失败响应或者超时，协调者会发送中止消息给所有参与者，参与者执行事务回滚操作并释放相关资源。

2PC协议的优点是可以保证分布式系统中的强一致性，所有参与者在提交前都会预留资源并进行准备操作，只有在所有参与者都准备就绪时才进行最终提交。但是2PC也存在一些缺点，例如协调者单点故障可能导致整个系统阻塞，同时在协调者与参与者之间的网络通信也需要保证可靠性。

除了2PC协议，还有其他一些分布式事务协议可以用于保证强一致性，如三阶段提交（Three-Phase Commit，简称3PC）协议、基于消息队列的事务等。具体选择哪种协议取决于应用需求和系统特点。

需要注意的是，分布式一致性是一个复杂的问题，没有一种通用的解决方案适用于所有情况。在设计和实现分布式系统时，需要综合考虑业务需求、性能、可靠性等因素，并根据具体情况选择适合的分布式事务方案。

## 6、简述一下分布式事务saga和tcc的区别

| 特性           | **Saga**                                   | **TCC (Try-Confirm-Cancel)**           |
| :------------- | :----------------------------------------- | :------------------------------------- |
| **基本思想**   | 长事务拆分为多个本地事务，通过补偿机制回滚 | 每个操作分两阶段（Try→Confirm/Cancel） |
| **事务粒度**   | 粗粒度（业务操作级）                       | 细粒度（资源预留级）                   |
| **一致性保证** | 最终一致性                                 | 强一致性（类似2PC）                    |
| **实现复杂度** | 较低（只需正向+逆向操作）                  | 较高（需实现Try/Confirm/Cancel三接口） |
| **锁资源时间** | 不锁定资源                                 | Try阶段锁定资源                        |
| **适用场景**   | 长周期事务（秒级~分钟级）                  | 短周期事务（毫秒级~秒级）              |
| **典型应用**   | 订单+库存+物流等跨服务流程                 | 账户扣款、库存预留等高一致性场景       |



# 智力题

## 1、一个 7g 和一个 2g 的砝码 3次 把140g的盐分成50g和90g

第一次：等分 50和90为  70 70

第二次.  7g 和2g  ，取出一个70中的9g  ,  61  70

第三次.利用 上一次取出的9g和2g砝码，取出61中的11克，前面的9 和 11 都放进70

## 2、有20瓶药丸,有19瓶是1g/颗,有一瓶是1.1g/颗。如何在称一次的情况下称出1.1g的那瓶药丸(药丸可拿出来，每瓶药丸够多)

 把每瓶的药丸都编号序号1-20，然后依次从瓶子里取出1-20个药丸进行称重M，然后最后多出多少重量M-210 就是有多少个1.1的药丸，然后对应瓶子的编号就是假药的1.1g。

## 3、N（4≤N小于≤8）个球，怎样用最少的次数找出较重的那个球。

偶数先取出N-2个球进行平均称，如果左右2边都相等，那就称剩下的2个球，如果不相等，就取重的那一栏进行对半称，然后进行上述对比操作。

奇数就取出N-1个球进行对半称，然后原理同上。

## 4、一池子水 有5L,7L的圆柱体水杯 现需要配出6L水 问你怎么配 为什么这么配?

第一步把7L水杯装满倒入空5L杯中（还剩2L）；

第二步把5L水杯的水倒掉，7L水杯里面的2L水导入到5L杯中，7L水杯再装满，然后把5L的水杯倒满，还剩4L倒给5L的水杯。

第三步7L的水杯倒满，再把水倒入装有4L水的5L水杯，就剩下6L的水了。

## 5、时针分针从12点开始 第一次重合在几点几分

设经过x小时,分针压过时针1圈

已知分针的速度为60个分针刻度/小时.那么时针的速度是5个刻度/小时

分针走的路程-时针走的路程=60

60x-5x=60

55x=60

x=60/55

x=12/11（小时）

12/11小时=720/11分钟≈65.45分钟

即1点5分27秒再次重合

## 6、公司有100人，会C语言的有75人，会JAVA语言的有90人，会GO语言的有60人，3种语言都会的最多和最少有多少人？

最多为60，取交集

最少为25，100 -（25 + 10 + 40）

## 7、房间里有一个灯泡，房间外有三个开关，问在只能进入房间一次的前提下，如何确定哪一个开关可以控制这个灯泡

将开关分为123号开关，打开1号开关20分钟后，关闭1号开关，打开二号开关，然后进入房间，若此时灯泡亮了，则2号开关是控制开关，若此时灯泡不亮，用手摸灯泡，如果是热的，证明1号开关是控制开关，若此时灯泡不热不亮，则3号开关是控制开关

## 8、有容量分别为10L、7L、3L的容器，10L容器中装满⽔。请问如何将10L容器中的⽔平均分成两份？

 答案:

```
①.10L杯中水先倒满7L杯子.`
 `②7L杯子连续倒满3L杯子两次并转入10L杯子，这样十升杯中为九升水，七升杯为一升.`
 `③将七升杯中一升水倒入三升杯.`
 `④将十升杯中水倒满七升杯.`
 `⑤再将七升杯中水倒入已经有一升水的三升杯，那么七升杯子里就剩五升水了.`
 `⑥最后将三升水杯中水放入十升水杯就成五升水了，正好平分。
```

# 技术选型

## 1、mongodb的优势在哪？对比redis？

MongoDB和Redis都是非常流行的数据库系统，它们在许多方面有不同的特点和优势。下面是MongoDB相对于Redis的一些优势：

1. 数据模型：
   - MongoDB：MongoDB采用文档模型，存储数据以灵活的、自描述的文档格式（BSON）的方式。这种模型允许存储复杂的数据结构，并且能够支持大量的字段和嵌套层次结构。
   - Redis：Redis则是一种键值对存储系统，它将简单的键值对映射到内存中进行快速访问，适合缓存和简单的数据结构操作。
2. 数据持久化：
   - MongoDB：MongoDB支持数据的持久化存储，可以将数据写入磁盘以实现数据的持久性。它提供了多种持久化选项，包括单节点的持久化和分布式复制的故障转移和数据冗余备份。
   - Redis：Redis通常将数据存储在内存中，虽然也提供了持久化选项，但默认情况下数据是不持久化的。持久化可以通过快照和追加日志两种方式来实现。
3. 查询和查询语言：
   - MongoDB：MongoDB提供了强大的查询功能，支持复杂的查询语句和多种运算符，例如范围查询、聚合管道、文本搜索和地理空间查询等。它的查询语言（MongoDB Query Language）比Redis更为灵活和功能丰富。
   - Redis：Redis的查询功能较为简单，主要支持根据键来获取值，以及一些基本的字符串匹配和排序操作。它不支持像MongoDB那样复杂的查询语法。
4. 数据量和可扩展性：
   - MongoDB：MongoDB具有良好的可扩展性，适用于处理大型数据集和高并发负载。它可以在分布式集群环境中进行水平扩展，支持自动数据分片和负载均衡。
   - Redis：Redis的可扩展性相对较弱，它通常用于处理较小规模的数据集和高速读写操作。虽然Redis支持主从复制和分区，但在大规模和高并发场景下的扩展性有限。

## 2、gaussdb对比mysql的优势？

GaussDB和MySQL是两种不同类型的数据库管理系统，它们在一些方面有不同的特点和优势。下面是GaussDB相对于MySQL的一些优势：

1. **高可伸缩性**：
   - GaussDB：作为华为公司开发的数据库管理系统，GaussDB具有出色的可伸缩性。它可以在大规模数据和高并发负载下进行水平扩展，适用于处理大型企业级应用。GaussDB可以通过动态添加节点来实现扩容，以满足不断增长的数据需求。
   - MySQL：MySQL在小型到中型应用中具有良好的可扩展性。虽然MySQL也支持主从复制、分区和集群等方式来实现扩展，但相对GaussDB而言，在大规模和高并发场景下的扩展性可能不如GaussDB。
2. **全面的功能和特性**：
   - GaussDB：GaussDB提供了许多高级功能和特性，例如支持大数据处理、并行查询、在线数据迁移、实时分析和机器学习等。它还具有高可用性和容灾能力，支持主备复制、故障恢复和数据备份等功能。另外，GaussDB采用了自主研发的多维度优化技术，以提升查询性能和存储压缩率。
   - MySQL：MySQL是一个简单易用的数据库，提供了基本的数据库功能，如索引、事务处理和数据备份和恢复等。虽然MySQL也有一些扩展功能，如存储过程、触发器、视图等，但相对于GaussDB而言，功能上的差距可能较大。
3. **支持大数据场景**：
   - GaussDB：GaussDB专注于支持大数据场景和企业级应用。它具有强大的数据处理能力，可以处理海量数据和复杂查询，并提供高并发访问性能。此外，GaussDB还支持与其他大数据组件的集成，如Hadoop、Spark和HBase等。
   - MySQL：MySQL在处理大规模数据和复杂查询方面的能力相对较弱。虽然MySQL可以通过分区和集群来扩展，但相对于GaussDB而言，它可能更适合中小型应用。

需要注意的是，GaussDB和MySQL在不同的应用场景中有各自的优点和适用性。选择适合自己需求的数据库取决于应用场景、性能需求、数据规模和团队技术能力等因素。

希望以上比较对您有所帮助。如有任何进一步的问题，请随时提问。
